{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b76a8c0d",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a234a155",
   "metadata": {},
   "source": [
    "## Import dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "df341691",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install -U dspy datasets tabulate duckdb pandas numpy ipywidgets \"sqlglot[rs]\" wandb --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4329c80c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import dspy\n",
    "from datasets import load_dataset\n",
    "import tabulate\n",
    "import pandas as pd\n",
    "import os\n",
    "from dotenv import load_dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "288f15f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv(\".env.local\")\n",
    "openai_api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "if not openai_api_key:\n",
    "    raise ValueError(\"OPENAI_API_KEY not found in environment variables\")\n",
    "\n",
    "wandb_api_key = os.getenv(\"WANDB_API_KEY\")\n",
    "if not wandb_api_key:\n",
    "    raise ValueError(\"WANDB_API_KEY not found in environment variables\")\n",
    "\n",
    "lm = dspy.LM(\"openai/gpt-3.5-turbo-0125\", api_key=openai_api_key, temperature=1, max_tokens=4000)\n",
    "reflection_lm = dspy.LM(\"openai/gpt-5-mini\", api_key=openai_api_key, temperature=1, max_tokens=16000)\n",
    "dspy.configure(lm=lm)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1e655b0",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "aef6f3c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = load_dataset(\"gretelai/synthetic_text_to_sql\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13420ef6",
   "metadata": {},
   "source": [
    "# Set up DSPy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7cab5f8",
   "metadata": {},
   "source": [
    "## Set up Signature and Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d4380853",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ProblemDef(dspy.Signature):\n",
    "    \"\"\"You are a database expert. You are provided with context for how some table(s) were constructed, and a natural language prompt for what the user wants. Your job is to write a SQL query to provide them with the required data.\"\"\"\n",
    "    \n",
    "    sql_context: str = dspy.InputField(description=\"SQL queries for creating the table(s) and loading some data\")\n",
    "    sql_prompt: str = dspy.InputField(description=\"User's natural language prompt\")\n",
    "    sql: str = dspy.OutputField(description=\"SQL query that delivers on the user's request. Format as code that can be directly run without any changes – do not use new lines or anything else of that sort.\")\n",
    "\n",
    "program = dspy.ChainOfThought(ProblemDef)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c92e6cce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install duckdb pandas numpy sqlglot --quiet\n",
    "import duckdb, pandas as pd, numpy as np, re\n",
    "import sqlglot\n",
    "from sqlglot import parse_one\n",
    "\n",
    "_ORDER_BY = re.compile(r\"\\border\\s+by\\b\", re.IGNORECASE)\n",
    "\n",
    "def _split_sql_statements(script: str):\n",
    "    out, buf, q = [], [], None\n",
    "    i, n = 0, len(script)\n",
    "    while i < n:\n",
    "        ch = script[i]\n",
    "        if q:\n",
    "            buf.append(ch)\n",
    "            if ch == q:\n",
    "                if i + 1 < n and script[i+1] == q:\n",
    "                    buf.append(script[i+1]); i += 1\n",
    "                else:\n",
    "                    q = None\n",
    "        else:\n",
    "            if ch in (\"'\", '\"', \"`\"):\n",
    "                q = ch; buf.append(ch)\n",
    "            elif ch == ';':\n",
    "                s = \"\".join(buf).strip()\n",
    "                if s: out.append(s)\n",
    "                buf = []\n",
    "            else:\n",
    "                buf.append(ch)\n",
    "        i += 1\n",
    "    tail = \"\".join(buf).strip()\n",
    "    if tail: out.append(tail)\n",
    "    return out\n",
    "\n",
    "import re\n",
    "from sqlglot import parse_one\n",
    "\n",
    "_SQLITE_DATE_RE = re.compile(\n",
    "    r\"\"\"\\bdate\\s*\\(\\s*'now'\\s*(?:,\\s*'([+-])\\s*(\\d+)\\s*(year|month|day)s?'\\s*)?\\)\"\"\",\n",
    "    re.IGNORECASE,\n",
    ")\n",
    "_SQLITE_DATETIME_RE = re.compile(\n",
    "    r\"\"\"\\bdatetime\\s*\\(\\s*'now'\\s*(?:,\\s*'([+-])\\s*(\\d+)\\s*(year|month|day|hour|minute|second)s?'\\s*)?\\)\"\"\",\n",
    "    re.IGNORECASE,\n",
    ")\n",
    "\n",
    "def _normalize_sqlite_dates(sql: str) -> str:\n",
    "    # date('now') or date('now','-1 year') -> CURRENT_DATE +/- INTERVAL 'N unit'\n",
    "    def _date_subst(m):\n",
    "        sign, num, unit = m.group(1), m.group(2), m.group(3)\n",
    "        if not sign:  # just date('now')\n",
    "            return \"CURRENT_DATE\"\n",
    "        op = \"-\" if sign == \"-\" else \"+\"\n",
    "        return f\"CURRENT_DATE {op} INTERVAL '{num} {unit.lower()}'\"\n",
    "    sql = _SQLITE_DATE_RE.sub(_date_subst, sql)\n",
    "\n",
    "    # datetime('now') / datetime('now','+/-N unit') -> CURRENT_TIMESTAMP +/- INTERVAL 'N unit'\n",
    "    def _dt_subst(m):\n",
    "        sign, num, unit = m.group(1), m.group(2), m.group(3)\n",
    "        if not sign:\n",
    "            return \"CURRENT_TIMESTAMP\"\n",
    "        op = \"-\" if sign == \"-\" else \"+\"\n",
    "        return f\"CURRENT_TIMESTAMP {op} INTERVAL '{num} {unit.lower()}'\"\n",
    "    sql = _SQLITE_DATETIME_RE.sub(_dt_subst, sql)\n",
    "\n",
    "    return sql\n",
    "\n",
    "def _mysql_to_duckdb(stmt: str) -> str:\n",
    "    s = _normalize_sqlite_dates(stmt)  # <-- NEW: normalize SQLite first\n",
    "    try:\n",
    "        return parse_one(s, read=\"mysql\").sql(dialect=\"duckdb\")\n",
    "    except Exception:\n",
    "        # minimal fallbacks for MySQLisms if parse fails\n",
    "        s = re.sub(r\"`([^`]+)`\", r'\"\\1\"', s)\n",
    "        s = re.sub(\n",
    "            r\"DATE_SUB\\s*\\(\\s*(CURRENT_DATE|NOW\\(\\))\\s*,\\s*INTERVAL\\s+(\\d+)\\s+(YEAR|MONTH|DAY)\\s*\\)\",\n",
    "            lambda m: f\"{'CURRENT_DATE' if m.group(1).startswith('CURRENT') else 'CURRENT_DATE'} - INTERVAL '{m.group(2)} {m.group(3).lower()}'\",\n",
    "            s, flags=re.IGNORECASE,\n",
    "        )\n",
    "        s = re.sub(\n",
    "            r\"DATE_ADD\\s*\\(\\s*(CURRENT_DATE|NOW\\(\\))\\s*,\\s*INTERVAL\\s+(\\d+)\\s+(YEAR|MONTH|DAY)\\s*\\)\",\n",
    "            lambda m: f\"{'CURRENT_DATE' if m.group(1).startswith('CURRENT') else 'CURRENT_DATE'} + INTERVAL '{m.group(2)} {m.group(3).lower()}'\",\n",
    "            s, flags=re.IGNORECASE,\n",
    "        )\n",
    "        s = re.sub(r\"\\bIFNULL\\s*\\(\", \"COALESCE(\", s, flags=re.IGNORECASE)\n",
    "        s = re.sub(r\"\\bLOCATE\\s*\\(\\s*([^,]+)\\s*,\\s*([^)]+)\\)\", r\"STRPOS(\\2, \\1)\", s, flags=re.IGNORECASE)\n",
    "        return s\n",
    "\n",
    "def _normalize_df(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    df = df.copy()\n",
    "    for c in df.columns:\n",
    "        if df[c].dtype == \"O\":\n",
    "            try:\n",
    "                df[c] = pd.to_numeric(df[c])\n",
    "            except Exception:\n",
    "                pass\n",
    "    return df.replace({np.nan: None})\n",
    "\n",
    "def _exec_script_capture_last_select(con, script: str):\n",
    "    last_df, last_sel_sql = None, None\n",
    "    for raw in _split_sql_statements(script):\n",
    "        stmt = _mysql_to_duckdb(raw)\n",
    "        # detect SELECT after minimal comment strip\n",
    "        s = re.sub(r\"^\\s*(--[^\\n]*\\n|/\\*.*?\\*/\\s*)*\", \"\", stmt, flags=re.DOTALL)\n",
    "        if re.match(r\"(?is)^\\s*(with\\b.*?select|select)\\b\", s):\n",
    "            last_df = con.execute(stmt).fetchdf()\n",
    "            last_sel_sql = stmt\n",
    "        else:\n",
    "            con.execute(stmt)\n",
    "    if last_df is not None:\n",
    "        last_df = _normalize_df(last_df)\n",
    "    return last_df, last_sel_sql\n",
    "\n",
    "def evaluate_sql(sql_context: str, golden_sql: str, predicted_sql: str):\n",
    "    con = duckdb.connect(\":memory:\")\n",
    "\n",
    "    # context\n",
    "    try:\n",
    "        for raw in _split_sql_statements(sql_context):\n",
    "            con.execute(_mysql_to_duckdb(raw))\n",
    "    except Exception as e:\n",
    "        return 0, {\"reason\": \"context_error\", \"detail\": str(e)}\n",
    "\n",
    "    # golden\n",
    "    try:\n",
    "        gold_df, gold_last_select = _exec_script_capture_last_select(con, golden_sql)\n",
    "    except Exception as e:\n",
    "        return 0, {\"reason\": \"gold_error\", \"detail\": str(e)}\n",
    "    if gold_df is None:\n",
    "        return 0, {\"reason\": \"gold_no_select\", \"detail\": \"No SELECT in golden_sql.\"}\n",
    "\n",
    "    # predicted\n",
    "    try:\n",
    "        pred_df, pred_last_select = _exec_script_capture_last_select(con, predicted_sql)\n",
    "    except Exception as e:\n",
    "        return 0, {\"reason\": \"pred_error\", \"detail\": str(e)}\n",
    "    if pred_df is None:\n",
    "        return 0, {\"reason\": \"pred_no_select\", \"detail\": \"No SELECT in predicted_sql.\"}\n",
    "\n",
    "    # column alignment (allow pred supersets; else try set/positional)\n",
    "    gold_cols, pred_cols = list(gold_df.columns), list(pred_df.columns)\n",
    "    if gold_cols == pred_cols:\n",
    "        pass\n",
    "    elif set(gold_cols).issubset(pred_cols):\n",
    "        pred_df = pred_df[gold_cols]\n",
    "    elif set(gold_cols) == set(pred_cols):\n",
    "        pred_df = pred_df[gold_cols]\n",
    "    elif gold_df.shape[1] == pred_df.shape[1]:\n",
    "        new_names = [f\"c{i}\" for i in range(gold_df.shape[1])]\n",
    "        gold_df = gold_df.copy(); pred_df = pred_df.copy()\n",
    "        gold_df.columns = new_names; pred_df.columns = new_names\n",
    "    else:\n",
    "        return 0, {\"reason\": \"column_mismatch\",\n",
    "                   \"detail\": f\"Different number of columns: expected {gold_df.shape[1]}, got {pred_df.shape[1]}\"}\n",
    "\n",
    "    # ordering rule from gold's last SELECT\n",
    "    gold_has_order = bool(_ORDER_BY.search(gold_last_select or \"\"))\n",
    "    if not gold_has_order:\n",
    "        try:\n",
    "            g = gold_df.sort_values(by=list(gold_df.columns), kind=\"mergesort\").reset_index(drop=True)\n",
    "            p = pred_df.sort_values(by=list(gold_df.columns), kind=\"mergesort\").reset_index(drop=True)\n",
    "        except Exception:\n",
    "            g = gold_df.reset_index(drop=True); p = pred_df.reset_index(drop=True)\n",
    "    else:\n",
    "        g = gold_df.reset_index(drop=True); p = pred_df.reset_index(drop=True)\n",
    "\n",
    "    # value compare\n",
    "    if g.shape != p.shape:\n",
    "        return 0, {\"reason\": \"shape_mismatch\", \"detail\": f\"gold {g.shape} vs pred {p.shape}\"}\n",
    "\n",
    "    for c in g.columns:\n",
    "        if pd.api.types.is_numeric_dtype(g[c]) and pd.api.types.is_numeric_dtype(p[c]):\n",
    "            if not np.allclose(g[c].values, p[c].values, rtol=1e-6, atol=1e-8, equal_nan=True):\n",
    "                return 0, {\"reason\": \"value_mismatch\", \"detail\": f\"Numeric mismatch in '{c}'\",\n",
    "                           \"gold_head\": g.head(10).to_dict(\"records\"),\n",
    "                           \"pred_head\": p.head(10).to_dict(\"records\")}\n",
    "        else:\n",
    "            eq = [(x == y) or (x is None and y is None) for x, y in zip(g[c].values, p[c].values)]\n",
    "            if not all(eq):\n",
    "                return 0, {\"reason\": \"value_mismatch\", \"detail\": f\"Mismatch in '{c}'\",\n",
    "                           \"gold_head\": g.head(10).to_dict(\"records\"),\n",
    "                           \"pred_head\": p.head(10).to_dict(\"records\")}\n",
    "    return 1, None\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb24b156",
   "metadata": {},
   "source": [
    "## Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "936c6363",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Context: CREATE TABLE upgrades (id INT, cost FLOAT, type TEXT); INSERT INTO upgrades (id, cost, type) VALUES (1, 500, 'Insulation'), (2, 1000, 'HVAC'), (3, 1500, 'Lighting');\n",
      "Prompt: Find the energy efficiency upgrades with the highest cost and their types.\n",
      "Golden sql: SELECT type, cost FROM (SELECT type, cost, ROW_NUMBER() OVER (ORDER BY cost DESC) as rn FROM upgrades) sub WHERE rn = 1;\n",
      "Prediction(\n",
      "    reasoning='To find the energy efficiency upgrade with the highest cost and its type, we can simply select the row from the `upgrades` table where the `cost` is equal to the maximum cost in the table.',\n",
      "    sql='SELECT * FROM upgrades WHERE cost = (SELECT MAX(cost) FROM upgrades)'\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "demo_index = 4\n",
    "context = ds['train'][demo_index]['sql_context']\n",
    "prompt = ds['train'][demo_index]['sql_prompt']\n",
    "golden_sql = ds['train'][demo_index]['sql']\n",
    "\n",
    "print(f\"Context: {context}\")\n",
    "print(f\"Prompt: {prompt}\")\n",
    "print(f\"Golden sql: {golden_sql}\")\n",
    "result = program(sql_context=context, sql_prompt=prompt)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "42b7fd89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 None\n"
     ]
    }
   ],
   "source": [
    "score, info = evaluate_sql(context, golden_sql, result.sql)\n",
    "print(score, info)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58142861",
   "metadata": {},
   "source": [
    "## Environment didn't work, let's use LLM as Judge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1c72a279",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Judge(dspy.Signature):\n",
    "    \"\"\"You are required to judge two SQL queries for functional similarity. You will be given a context of how the table(s) and data were created, and the natural language prompt from the user\"\"\"\n",
    "\n",
    "    sql_context: str = dspy.InputField(description=\"SQL statement(s) creating the table(s) and the input data\")\n",
    "    sql_prompt: str = dspy.InputField(description=\"Natural language prompt from the user\")\n",
    "    golden_sql: str = dspy.InputField(description=\"The golden SQL query from our dataset\")\n",
    "    candidate_sql: str = dspy.InputField(description=\"A SQL query generated by a model for the same prompt\")\n",
    "    similar: bool = dspy.OutputField(description=\"True if the candidate SQL query is functionally similar to the golden SQL query\")\n",
    "\n",
    "judge = dspy.ChainOfThought(Judge)\n",
    "judge.lm = reflection_lm\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1677bf72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Context: CREATE TABLE upgrades (id INT, cost FLOAT, type TEXT); INSERT INTO upgrades (id, cost, type) VALUES (1, 500, 'Insulation'), (2, 1000, 'HVAC'), (3, 1500, 'Lighting');\n",
      "Prompt: Find the energy efficiency upgrades with the highest cost and their types.\n",
      "Golden SQL: SELECT type, cost FROM (SELECT type, cost, ROW_NUMBER() OVER (ORDER BY cost DESC) as rn FROM upgrades) sub WHERE rn = 1;\n",
      "Candidate SQL: SELECT * FROM upgrades WHERE cost = (SELECT MAX(cost) FROM upgrades)\n",
      "Judge Response: Prediction(\n",
      "    reasoning='The golden SQL query uses a subquery with the ROW_NUMBER() window function to rank the rows by cost in descending order and then filters the row with the highest cost. On the other hand, the candidate SQL query simply retrieves the rows where the cost is equal to the maximum cost in the table. The candidate query does not consider ties in cost, which may lead to different results.',\n",
      "    similar=False\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "judge_response = judge(sql_context=context, sql_prompt=prompt, golden_sql=golden_sql, candidate_sql=result.sql)\n",
    "print(f\"Context: {context}\")\n",
    "print(f\"Prompt: {prompt}\")\n",
    "print(f\"Golden SQL: {golden_sql}\")\n",
    "print(f\"Candidate SQL: {result.sql}\")\n",
    "print(f\"Judge Response: {judge_response}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7746087",
   "metadata": {},
   "source": [
    "# Get ready to GEPA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c35b7379",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install datasets dspy-ai\n",
    "import math, random\n",
    "from typing import Callable, List, Tuple, Optional\n",
    "from datasets import Dataset, DatasetDict\n",
    "from dspy import GEPA\n",
    "\n",
    "def split_for_gepa(\n",
    "    ds: Dataset,\n",
    "    to_example: Callable[[dict], \"dspy.Example\"],\n",
    "    val_size: float = 0.15,\n",
    "    seed: int = 42,\n",
    "    group_col: Optional[str] = None,\n",
    "    stratify_col: Optional[str] = None,\n",
    ") -> Tuple[List[\"dspy.Example\"], List[\"dspy.Example\"]]:\n",
    "    \"\"\"\n",
    "    Return (train_set, val_set) as lists of dspy.Example.\n",
    "    - If group_col is set: group-aware split (no group leakage).\n",
    "    - Else if stratify_col is set: use HF stratified split.\n",
    "    - Else: random split.\n",
    "    \"\"\"\n",
    "    assert 0.0 < val_size < 1.0, \"val_size must be in (0,1)\"\n",
    "    rng = random.Random(seed)\n",
    "\n",
    "    # --- Group-aware split (preferred for text2sql) ---\n",
    "    if group_col:\n",
    "        groups = ds[group_col]\n",
    "        # Build group -> indices\n",
    "        g2idx = {}\n",
    "        for i, g in enumerate(groups):\n",
    "            g2idx.setdefault(g, []).append(i)\n",
    "        uniq_groups = list(g2idx.keys())\n",
    "        rng.shuffle(uniq_groups)\n",
    "        n_val_groups = max(1, math.floor(val_size * len(uniq_groups)))\n",
    "        val_groups = set(uniq_groups[:n_val_groups])\n",
    "\n",
    "        val_idx = [i for g in val_groups for i in g2idx[g]]\n",
    "        train_idx = [i for g in uniq_groups[n_val_groups:] for i in g2idx[g]]\n",
    "\n",
    "        # Edge case: if a group is gigantic, ensure both splits non-empty\n",
    "        if not train_idx or not val_idx:\n",
    "            # fallback: plain random split\n",
    "            perm = list(range(len(ds)))\n",
    "            rng.shuffle(perm)\n",
    "            cut = max(1, math.floor(val_size * len(ds)))\n",
    "            val_idx, train_idx = perm[:cut], perm[cut:]\n",
    "\n",
    "        ds_train = ds.select(train_idx)\n",
    "        ds_val = ds.select(val_idx)\n",
    "\n",
    "    # --- Stratified split (when you have a label/cluster column) ---\n",
    "    elif stratify_col:\n",
    "        # HF does stratify on categorical-like columns\n",
    "        parts: DatasetDict = ds.train_test_split(\n",
    "            test_size=val_size,\n",
    "            seed=seed,\n",
    "            stratify_by_column=stratify_col,\n",
    "        )\n",
    "        ds_train, ds_val = parts[\"train\"], parts[\"test\"]\n",
    "\n",
    "    # --- Simple random split ---\n",
    "    else:\n",
    "        parts: DatasetDict = ds.train_test_split(test_size=val_size, seed=seed)\n",
    "        ds_train, ds_val = parts[\"train\"], parts[\"test\"]\n",
    "\n",
    "    # Map to dspy.Example lists\n",
    "    train_set = [to_example(r) for r in ds_train]\n",
    "    val_set = [to_example(r) for r in ds_val]\n",
    "    return train_set, val_set\n",
    "\n",
    "def to_dspy_example(row):\n",
    "    # mark inputs; leave gold 'sql' as label\n",
    "    return dspy.Example(\n",
    "        sql_prompt=row[\"sql_prompt\"],\n",
    "        sql_context=row[\"sql_context\"],\n",
    "        sql=row[\"sql\"],          # gold label\n",
    "    ).with_inputs(\"sql_prompt\", \"sql_context\")\n",
    "\n",
    "\n",
    "# call function that splits ds['train'] into train_set and val_set as needed\n",
    "# ds is your loaded HF dataset dict; we split ds[\"train\"]\n",
    "train_set, val_set = split_for_gepa(\n",
    "    ds[\"train\"],\n",
    "    to_dspy_example,          # your to_dspy_example(row)\n",
    "    val_size=0.5,\n",
    "    seed=42,\n",
    "    group_col=None,      # e.g., \"db_id\" if available\n",
    "    stratify_col=None,   # or a column like \"op_class\" if you want stratification\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "88d14596",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_variants_to_try = 20 # number of variants to test\n",
    "mini_batch_size = 20 # mini-batch size\n",
    "val_set_size = 200 # val-set size\n",
    "train_set_size = 200 # train-set size\n",
    "\n",
    "def budget_for_variants(N, V, k, slack=2):\n",
    "    # slack handles occasional extra probes/promotions\n",
    "    return V + N * (k + slack)\n",
    "\n",
    "def metric_with_feedback(example, pred, trace=None, pred_name=None, pred_trace=None):\n",
    "    judge_response = judge(sql_context=example.sql_context, sql_prompt=example.sql_prompt, golden_sql=example.sql, candidate_sql=pred.sql)\n",
    "    score = 0\n",
    "    if (judge_response.similar):\n",
    "        score = 1\n",
    "    return dspy.Prediction(score=score, feedback=judge_response.reasoning)\n",
    "\n",
    "val_for_tracking = val_set[:val_set_size]   # 128–512 is a good range\n",
    "train_set_for_optimization = train_set[:train_set_size]\n",
    "optimizer = GEPA(\n",
    "    metric=metric_with_feedback,\n",
    "    num_threads=32,\n",
    "    track_stats=True,\n",
    "    reflection_minibatch_size=mini_batch_size,\n",
    "    reflection_lm=reflection_lm,\n",
    "    use_wandb=True,\n",
    "    wandb_api_key=wandb_api_key,\n",
    "    log_dir=\"logs\",\n",
    "    auto=\"light\"   \n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f77daa2b",
   "metadata": {},
   "source": [
    "# Run GEPA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "940c1f37",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/10/14 16:55:28 INFO dspy.teleprompt.gepa.gepa: Running GEPA for approx 1180 metric calls of the program. This amounts to 2.95 full evals on the train+val set.\n",
      "2025/10/14 16:55:28 INFO dspy.teleprompt.gepa.gepa: Using 200 examples for tracking Pareto scores. You can consider using a smaller sample of the valset to allow GEPA to explore more diverse solutions within the same budget.\n",
      "/Users/raveesh/dev/text2sql/.venv/lib/python3.12/site-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'repr' attribute with value False was provided to the `Field()` function, which has no effect in the context it was used. 'repr' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.\n",
      "  warnings.warn(\n",
      "/Users/raveesh/dev/text2sql/.venv/lib/python3.12/site-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'frozen' attribute with value True was provided to the `Field()` function, which has no effect in the context it was used. 'frozen' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.\n",
      "  warnings.warn(\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /Users/raveesh/.netrc\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mraveeshbhalla90\u001b[0m (\u001b[33mraveeshbhalla90-personal\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.22.2"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/Users/raveesh/dev/text2sql/wandb/run-20251014_165529-tx1h8cjc</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/raveeshbhalla90-personal/text2sql/runs/tx1h8cjc' target=\"_blank\">floral-morning-17</a></strong> to <a href='https://wandb.ai/raveeshbhalla90-personal/text2sql' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/raveeshbhalla90-personal/text2sql' target=\"_blank\">https://wandb.ai/raveeshbhalla90-personal/text2sql</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/raveeshbhalla90-personal/text2sql/runs/tx1h8cjc' target=\"_blank\">https://wandb.ai/raveeshbhalla90-personal/text2sql/runs/tx1h8cjc</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Detected [dspy, litellm, openai] in use.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Use W&B Weave for improved LLM call tracing. Install Weave with `pip install weave` then add `import weave` to the top of your script.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: For more information, check out the docs at: https://weave-docs.wandb.ai/\n",
      "GEPA Optimization:   0%|          | 0/1180 [00:00<?, ?rollouts/s]2025/10/14 16:55:46 INFO dspy.evaluate.evaluate: Average Metric: 123.0 / 200 (61.5%)\n",
      "2025/10/14 16:55:46 INFO dspy.teleprompt.gepa.gepa: Iteration 0: Base program full valset score: 0.615\n",
      "GEPA Optimization:  17%|█▋        | 200/1180 [00:16<01:21, 12.09rollouts/s]2025/10/14 16:55:46 INFO dspy.teleprompt.gepa.gepa: Iteration 1: Selected program 0 score: 0.615\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 17.00 / 20 (85.0%): 100%|██████████| 20/20 [00:03<00:00,  6.64it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/10/14 16:55:49 INFO dspy.evaluate.evaluate: Average Metric: 17.0 / 20 (85.0%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/10/14 16:56:13 INFO dspy.teleprompt.gepa.gepa: Iteration 1: Proposed new text for predict: You are a SQL/database expert assistant. You will be given:\n",
      "- sql_context: SQL DDL/DML statements that define the available table schemas and may include example INSERTs.\n",
      "- sql_prompt: a natural-language request asking for data retrieval, insertion, deletion, or aggregation based on the provided context.\n",
      "\n",
      "Your job: produce (1) a short, clear reasoning statement describing how you will satisfy the prompt using the provided schemas, and (2) a single SQL statement that implements that plan against the provided schema.\n",
      "\n",
      "Rules and conventions to follow:\n",
      "\n",
      "1. Output format\n",
      "   - Always produce two labeled parts: a brief \"reasoning\" and then the \"sql\".\n",
      "   - Keep reasoning concise (one or two sentences). It should state any important assumptions and the approach (e.g., which table(s) used, filters, aggregates, joins).\n",
      "   - The \"sql\" must contain exactly one valid SQL statement (terminated with a semicolon is optional but acceptable). Do not include any other unrelated SQL statements.\n",
      "\n",
      "2. Use only the provided schema and column names\n",
      "   - Do not invent tables or columns not present in sql_context.\n",
      "   - Use the column names and table names exactly as provided (case-sensitive only if context implies so).\n",
      "   - If the prompt requires data not possible from the given schema, state that clearly in the reasoning and, if sensible, return the closest possible query or request clarification.\n",
      "\n",
      "3. Choosing the correct aggregation or operation\n",
      "   - Use SUM(column) when the prompt asks for a total amount stored in a numeric column (e.g., \"total number of pallets\" when a pallets_handled column exists).\n",
      "   - Use COUNT(*) or COUNT(column) when the prompt asks for the number of rows/occurrences. Use COUNT(DISTINCT col) when unique counts are requested.\n",
      "   - For averages use AVG(column). For extremes use MIN(column) or MAX(column).\n",
      "   - For grouped results use GROUP BY and label aggregated outputs with AS for clarity.\n",
      "   - When filtering groups (e.g., \"routes with more than 5 records\"), use HAVING COUNT(*) > 5 (or the appropriate aggregate).\n",
      "\n",
      "4. Joins, subqueries, and EXISTS\n",
      "   - When combining related tables prefer explicit JOINs (INNER JOIN, LEFT JOIN) for clarity and efficiency, especially when the example feedback indicates a join is preferable.\n",
      "   - Subqueries are acceptable (IN, EXISTS) when they are simpler; prefer NOT EXISTS for \"has not\" style logic (e.g., employees who have NOT completed X).\n",
      "   - Use table aliases for readability in joins.\n",
      "\n",
      "5. Filtering and predicates\n",
      "   - Use WHERE for row-level filters (e.g., equality on strings, numeric comparisons, dates).\n",
      "   - Use string matching with LIKE '%text%' when the prompt implies substring matching (e.g., \"AI ethics\" in course names).\n",
      "   - Use explicit date formats from the context (e.g., 'YYYY-MM-DD') and equality checks for specific dates unless a range is requested.\n",
      "\n",
      "6. Limits, ordering, and top-N\n",
      "   - For \"top N\" requests, compute the metric (AVG, SUM, COUNT, etc.), ORDER BY that metric DESC (or ASC if specified) and apply LIMIT N.\n",
      "   - Label the metric column with AS.\n",
      "\n",
      "7. INSERT and DELETE operations\n",
      "   - For INSERTs, list target columns explicitly and supply VALUES matching types; quote string/date literals with single quotes.\n",
      "   - For DELETEs, always include a WHERE clause that matches the user's condition exactly to avoid deleting all rows.\n",
      "\n",
      "8. Ambiguity and assumptions\n",
      "   - If the prompt is ambiguous (e.g., \"total number\" could mean COUNT rows or SUM a numeric column), choose the most reasonable interpretation based on the schema and state that assumption in the reasoning.\n",
      "   - If multiple interpretations are reasonable, either (a) ask for clarification (briefly) in the reasoning, or (b) pick the most likely interpretation and note it in the reasoning.\n",
      "\n",
      "9. Efficiency and correctness\n",
      "   - Prefer JOINs over IN-subqueries when both are possible and feedback suggests join is better.\n",
      "   - Use DISTINCT when the prompt implies unique values.\n",
      "   - Use proper grouping and HAVING for group filters.\n",
      "\n",
      "10. Presentation and safety\n",
      "    - Keep outputs concise; do not output extra commentary beyond the \"reasoning\" and \"sql\".\n",
      "    - Use single quotes for string/date literals and TRUE/FALSE for booleans if the schema uses them.\n",
      "    - If the requested action cannot be performed safely with the given schema (e.g., missing columns for an insertion), explain that in the reasoning and do not produce an incorrect SQL.\n",
      "\n",
      "Example output pattern:\n",
      "reasoning\n",
      "<one or two sentences describing tables/filters/aggregations/assumptions>\n",
      "\n",
      "sql\n",
      "<single SQL statement>\n",
      "\n",
      "Follow these rules for every task.\n",
      "2025/10/14 16:56:16 INFO dspy.evaluate.evaluate: Average Metric: 16.0 / 20 (80.0%)\n",
      "2025/10/14 16:56:16 INFO dspy.teleprompt.gepa.gepa: Iteration 1: New subsample score is not better, skipping\n",
      "GEPA Optimization:  20%|██        | 240/1180 [00:46<03:37,  4.33rollouts/s]2025/10/14 16:56:16 INFO dspy.teleprompt.gepa.gepa: Iteration 2: Selected program 0 score: 0.615\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 15.00 / 20 (75.0%): 100%|██████████| 20/20 [00:03<00:00,  5.93it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/10/14 16:56:19 INFO dspy.evaluate.evaluate: Average Metric: 15.0 / 20 (75.0%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/10/14 16:56:49 INFO dspy.teleprompt.gepa.gepa: Iteration 2: Proposed new text for predict: You are a SQL-writing assistant and a database expert. You will be given two inputs:\n",
      "  - sql_prompt: a natural-language request describing the data the user wants.\n",
      "  - sql_context: DDL and sample DML (CREATE TABLE, INSERT, VIEW, etc.) showing table and column names, types, and sometimes helper views.\n",
      "\n",
      "Your job: produce a single correct SQL statement (or DDL/DML when the prompt requests creation/insertion) that directly answers sql_prompt using only the tables, views, columns and data available in sql_context. Also return a one- or two-sentence natural-language justification of the approach (how you mapped the prompt to SQL). Follow the rules, patterns and domain knowledge below.\n",
      "\n",
      "Input parsing and assumptions\n",
      "- Always use the exact table and column names present in sql_context. Do not invent tables or columns not shown.\n",
      "- If sql_context defines a view, prefer using the view when it already filters or restricts data relevant to the prompt.\n",
      "- If sql_context contains sample INSERTs, they only show example data — do not assume additional hidden rows beyond typical semantics.\n",
      "\n",
      "How to map natural-language requests to SQL\n",
      "- Aggregation:\n",
      "  - \"total\", \"sum\", \"total revenue\" -> SUM(...)\n",
      "  - \"average\" -> AVG(...)\n",
      "  - \"maximum\", \"max\" -> MAX(...)\n",
      "  - \"minimum\", \"min\" -> MIN(...)\n",
      "  - \"count\", \"how many\", \"number of\" -> COUNT(...) or COUNT(DISTINCT ...) if uniqueness is required\n",
      "  - When grouping by categories use GROUP BY for non-aggregated columns.\n",
      "  - Use HAVING to filter aggregated groups (e.g., HAVING COUNT(DISTINCT ...) > 1).\n",
      "- Filtering:\n",
      "  - Apply WHERE for row-level filters (e.g., region, year, status).\n",
      "  - For date ranges, use standard constructs: e.g. WHERE date_col >= 'YYYY-MM-DD' AND date_col < 'YYYY-MM-DD', or WHERE date_col >= DATE_SUB(CURRENT_DATE(), INTERVAL 1 WEEK). DATE_SUB(CURRENT_DATE(), INTERVAL n DAY/WEEK/MONTH) and CURDATE() / CURRENT_DATE() are acceptable in MySQL-style dialects.\n",
      "- Joins:\n",
      "  - Use INNER JOIN (JOIN) when the prompt requests an \"inner join\" or when you only want rows present in both tables.\n",
      "  - Use LEFT JOIN plus WHERE right_table.key IS NULL to find entities with no related rows (e.g., companies with no patents).\n",
      "  - Join on the columns that logically connect tables — use keys present in sql_context.\n",
      "- Aggregation + non-aggregated output:\n",
      "  - If you SELECT non-aggregated columns alongside aggregates, include those non-aggregated columns in GROUP BY per SQL standard.\n",
      "- DISTINCT:\n",
      "  - Use SELECT DISTINCT when the prompt requests unique values.\n",
      "  - Use COUNT(DISTINCT col) when the prompt asks for the count of distinct items.\n",
      "- Top/ordering:\n",
      "  - To return the single highest/lowest use ORDER BY <aggregate> DESC (or ASC) LIMIT 1.\n",
      "  - Only add ORDER BY when the user asks for sorted results or when selecting the top N.\n",
      "- Time differences and sessions:\n",
      "  - To compute session length use TIMESTAMPDIFF(unit, start, end) (MySQL) or appropriate dialect-specific function; then aggregate (AVG, SUM) as required.\n",
      "- DDL/DML tasks:\n",
      "  - If the prompt asks to create a table or insert a row, output a valid CREATE TABLE or INSERT statement that uses the columns/types/names asked for and matches the provided sql_context style (explicit column lists are preferred in INSERT).\n",
      "- Column aliasing and readability:\n",
      "  - Alias aggregates with clear names (e.g., AS total_revenue, AS average_session_length).\n",
      "  - Use table aliases (e.g., a, b) when joining for clarity, but keep them readable.\n",
      "\n",
      "Common SQL patterns and when to use them (explicit examples you should employ when relevant)\n",
      "- Sum of revenue across rows: SELECT SUM(quantity * unit_price) AS total_revenue FROM table WHERE ...;\n",
      "- Total by group: SELECT group_col, SUM(value) AS total FROM table WHERE ... GROUP BY group_col;\n",
      "- Count per group: SELECT col, COUNT(*) AS cnt FROM table WHERE ... GROUP BY col;\n",
      "- Count of distinct related items: SELECT p.name FROM parent p JOIN child c ON p.id = c.parent_id GROUP BY p.id HAVING COUNT(DISTINCT c.some_col) > 1;\n",
      "- Entities with no related rows: SELECT p.name FROM parent p LEFT JOIN child c ON p.id = c.parent_id WHERE c.id IS NULL;\n",
      "- Latest N or highest aggregate: SELECT key FROM table GROUP BY key ORDER BY AVG(metric) DESC LIMIT 1;\n",
      "- Date filtering for a quarter or year: use explicit date bounds (e.g., WHERE sale_date >= '2019-04-01' AND sale_date < '2019-07-01') rather than relying on ambiguous month names.\n",
      "- When sql_prompt asks \"for each X in each Y\" -> GROUP BY X, Y.\n",
      "- When sql_prompt asks for \"using an inner join\" -> use JOIN (not LEFT JOIN).\n",
      "\n",
      "Error handling, ambiguity, and questions\n",
      "- If the prompt is ambiguous (e.g., asks for \"recent\" but gives no timeframe, or asks to \"sort by genre\" but no genre exists in provided schema), ask one concise clarifying question instead of guessing.\n",
      "- If the prompt requests data that cannot be derived from the provided schema (no join path, missing columns), respond with a brief explanation of what's missing and ask for the needed schema/column.\n",
      "\n",
      "Style and output format\n",
      "- Return exactly two sections:\n",
      "  1) A one- or two-sentence reasoning/justification describing the approach.\n",
      "  2) The SQL statement only (no additional surrounding text).\n",
      "- The SQL should be syntactically valid for common SQL (MySQL-style functions like DATE_SUB, TIMESTAMPDIFF are acceptable). Use semicolon at the end.\n",
      "- Keep queries minimal and focused — do not include unnecessary ORDER BY clauses unless required by the prompt.\n",
      "- Use aliases and clear aggregate names.\n",
      "\n",
      "Examples of pitfalls to avoid (learned from prior cases)\n",
      "- Don’t omit SUM/AVG/COUNT when the prompt explicitly asks for totals/averages; include aggregation.\n",
      "- When the prompt asks for \"combined total for both years\", don’t group by year; sum across years instead.\n",
      "- When asked for the number of likes and shares per post, aggregate likes and shares per post (SUM) if likes/shares tables hold multiple rows per post.\n",
      "- If the prompt says \"using an inner join\", do not use LEFT JOIN.\n",
      "- When asked for the names of companies with no patents, either use LEFT JOIN ... IS NULL or a NOT IN / NOT EXISTS subquery; both are acceptable.\n",
      "- Use COUNT(DISTINCT ...) when the prompt asks for \"more than one country\" or similar distinct counts.\n",
      "\n",
      "If you follow these rules you will produce correct, understandable SQL queries that match the user's intent and the provided schema.\n",
      "2025/10/14 16:56:52 INFO dspy.evaluate.evaluate: Average Metric: 15.0 / 20 (75.0%)\n",
      "2025/10/14 16:56:52 INFO dspy.teleprompt.gepa.gepa: Iteration 2: New subsample score is not better, skipping\n",
      "GEPA Optimization:  24%|██▎       | 280/1180 [01:22<05:55,  2.53rollouts/s]2025/10/14 16:56:52 INFO dspy.teleprompt.gepa.gepa: Iteration 3: Selected program 0 score: 0.615\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 10.00 / 20 (50.0%): 100%|██████████| 20/20 [00:03<00:00,  5.25it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/10/14 16:56:56 INFO dspy.evaluate.evaluate: Average Metric: 10.0 / 20 (50.0%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/10/14 16:57:28 INFO dspy.teleprompt.gepa.gepa: Iteration 3: Proposed new text for predict: You are a SQL-writing assistant (a database expert). You will be given two inputs:\n",
      "- sql_context: a block of DDL and sample INSERT statements that defines table names, column names and types and gives example rows.\n",
      "- sql_prompt: a natural-language question or task describing the data the user wants.\n",
      "\n",
      "Your job: produce a single, correct SQL query (or DDL statement if the prompt explicitly requests creating a table) that answers the sql_prompt using the schema in sql_context. Also produce a short reasoning/explanation (1–3 sentences) describing the approach you took.\n",
      "\n",
      "Input format (what to expect)\n",
      "- sql_context: contains CREATE TABLE statements and optional INSERTs. Treat the schema (table names and column names/types) as authoritative. Sample INSERTs illustrate values and types but are not exhaustive.\n",
      "- sql_prompt: a natural-language instruction that may request selection, aggregation, grouping, filters by date/region/etc., creating a table, top-N, counts, averages, joins, etc.\n",
      "\n",
      "Output format (exact expectations)\n",
      "- First, a concise \"reasoning\" explanation (1–3 short sentences) explaining the approach and any important assumptions.\n",
      "- Then, the SQL statement only (in a single code block). The SQL must be executable against the schema provided (use the table/column names from sql_context). If the prompt explicitly asks to create a table produce a CREATE TABLE statement (use IF NOT EXISTS if the schema may already define it). Otherwise produce a SELECT (or other DML) statement.\n",
      "\n",
      "SQL style, correctness and conventions (rules and best practices you must follow)\n",
      "1. Use the schema from sql_context. Do not invent column names or tables. If a needed column is missing from the schema, ask a clarifying question instead of guessing.\n",
      "2. Prefer ANSI/portable SQL where possible. Use these common functions when the examples indicate them:\n",
      "   - date ranges: DATE_SUB(CURRENT_DATE, INTERVAL n MONTH) or DATE_SUB(CURDATE(), INTERVAL n MONTH)\n",
      "   - year/month extraction: EXTRACT(YEAR FROM date), EXTRACT(MONTH FROM date)\n",
      "   - quarter: QUARTER(date) and also validate YEAR(date) for year-scoped quarters\n",
      "   - CURRENT_DATE or CURDATE() for “today”\n",
      "   Use the function style consistent with the sql_context examples; if dialect is unclear, prefer EXTRACT and CURRENT_DATE.\n",
      "3. Aggregates must have readable aliases. Always alias aggregated columns (e.g., AS total_streams, AS average_budget).\n",
      "4. GROUP BY must include only the non-aggregated columns required by the SELECT. Avoid grouping by extra columns (e.g., avoid grouping by both id and name when only name is requested, unless necessary for correctness).\n",
      "5. Use explicit JOINs and ON clauses (JOIN ... ON ...) rather than commas. Use LEFT JOIN when the prompt asks to \"list all X and counts\" so items with zero matches are included. Use INNER JOIN when only matching rows are required.\n",
      "6. For \"top N per group\" tasks, use window functions (ROW_NUMBER() OVER (PARTITION BY group_col ORDER BY metric DESC)) and then filter on row number. For \"top N overall\" use ORDER BY ... DESC LIMIT N.\n",
      "7. For filters by date ranges like \"last N months\", \"last 12 months\", \"Q1 of 2021\", use appropriate date functions:\n",
      "   - last N months: WHERE date >= DATE_SUB(CURRENT_DATE, INTERVAL N MONTH)\n",
      "   - specific quarter/year: WHERE EXTRACT(YEAR FROM date) = 2021 AND QUARTER(date) = 1\n",
      "   - months/years: use EXTRACT or DATE_TRUNC equivalents\n",
      "8. Use DISTINCT only when explicitly required (e.g., \"companies that have received funding in both USA and Canada\" may require DISTINCT or grouping with HAVING COUNT(DISTINCT country) = 2).\n",
      "9. When counting or summing by categories, include an alias and ORDER BY if prompt requests a particular ordering (e.g., \"present in descending order of budget\").\n",
      "10. Minimize returning unnecessary columns: return only the columns asked for (and any additional columns strictly needed for correctness).\n",
      "11. When the prompt is ambiguous (e.g., \"top 3 initiatives in Kenya, Tanzania and Uganda\" — top 3 per country or top 3 combined?), ask a clarifying question instead of guessing.\n",
      "12. If the prompt asks for schema creation but the sql_context already contains a CREATE for the same table, prefer CREATE TABLE IF NOT EXISTS with a schema consistent with the context (or ask whether to recreate/replace).\n",
      "13. Use table aliases to keep SQL concise and readable (e.g., FROM programs p JOIN categories c ON ...).\n",
      "14. If the prompt requests listing items by month/quarter/year, include an extracted month/quarter/year column in the SELECT with a clear alias (e.g., EXTRACT(MONTH FROM date) AS month).\n",
      "15. For performance/clarity prefer joins + grouping/HAVING/window functions rather than correlated subqueries, unless a subquery is clearer or simpler.\n",
      "\n",
      "Common pitfalls to avoid (learned from examples)\n",
      "- Do not group by extra columns that change the aggregation semantics (e.g., grouping by both artist and country when the ask is total per artist).\n",
      "- When counting attendees per training and the prompt asks for all trainings, use LEFT JOIN so trainings with zero attendees are included.\n",
      "- When asked for “companies that received funding in both USA and Canada”, it is standard to either:\n",
      "   - use GROUP BY company_id HAVING COUNT(DISTINCT country) >= 2 (or =2 when only USA & Canada), or\n",
      "   - self-join fundings filtered to each country, or\n",
      "   - use an intersection/subquery. Do not merely filter WHERE country = 'USA' AND country = 'Canada' (impossible).\n",
      "- Prefer explicit date function usage for quarters and years rather than hard-coded date ranges unless the prompt gives explicit dates.\n",
      "- Always alias aggregates (SUM(... ) AS total), and use meaningful aliases matching the prompt.\n",
      "\n",
      "When to ask clarifying questions\n",
      "- Missing columns required by the prompt (e.g., prompt asks for department but table has none).\n",
      "- Ambiguities such as top-N per group vs top-N overall, which countries to include when prompt lists several regions, or whether date ranges are inclusive/exclusive.\n",
      "- If the prompt asks to \"create a table\" but does not specify columns or types and none are in sql_context.\n",
      "\n",
      "Response content requirements\n",
      "- Reasoning: 1–3 short sentences mentioning the join/group/filter/aggregation strategy and any assumptions.\n",
      "- SQL: single SQL statement appropriate to the prompt, syntactically consistent with the schema in sql_context, with proper aliases, grouping, ordering and limiting as required.\n",
      "\n",
      "Examples of patterns you should use (not exhaustive)\n",
      "- Sum per group: SELECT category, SUM(budget) AS total_budget FROM programs WHERE budget > 5000 GROUP BY category;\n",
      "- Last N months: WHERE donation_date >= DATE_SUB(CURRENT_DATE, INTERVAL 12 MONTH)\n",
      "- Top N per group: use ROW_NUMBER() OVER (PARTITION BY country ORDER BY budget DESC) and filter row_num <= 3\n",
      "- Count per month/year/type: SELECT EXTRACT(MONTH FROM date) AS month, incident_type, mine_location, COUNT(*) AS num_incidents FROM incidents WHERE EXTRACT(YEAR FROM date) = 2021 GROUP BY month, incident_type, mine_location ORDER BY month;\n",
      "\n",
      "Be concise and precise. If you cannot produce a correct SQL because of missing schema details or ambiguous requirements, ask one clear clarifying question.\n",
      "2025/10/14 16:57:32 INFO dspy.evaluate.evaluate: Average Metric: 12.0 / 20 (60.0%)\n",
      "2025/10/14 16:57:48 INFO dspy.evaluate.evaluate: Average Metric: 123.0 / 200 (61.5%)\n",
      "2025/10/14 16:57:48 INFO dspy.teleprompt.gepa.gepa: Iteration 3: Full valset score for new program: 0.615\n",
      "2025/10/14 16:57:48 INFO dspy.teleprompt.gepa.gepa: Iteration 3: Full train_val score for new program: 0.615\n",
      "2025/10/14 16:57:48 INFO dspy.teleprompt.gepa.gepa: Iteration 3: Individual valset scores for new program: [0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 0, 1, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 0, 0, 1, 1, 1, 0, 1, 0, 1, 1, 0, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 0, 1]\n",
      "2025/10/14 16:57:48 INFO dspy.teleprompt.gepa.gepa: Iteration 3: New valset pareto front scores: [0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 0, 0, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1]\n",
      "2025/10/14 16:57:48 INFO dspy.teleprompt.gepa.gepa: Iteration 3: Full valset pareto front score: 0.685\n",
      "2025/10/14 16:57:48 INFO dspy.teleprompt.gepa.gepa: Iteration 3: Updated valset pareto front programs: [{0, 1}, {0, 1}, {0, 1}, {0, 1}, {0, 1}, {0, 1}, {0, 1}, {0, 1}, {0, 1}, {0, 1}, {0, 1}, {0, 1}, {0, 1}, {1}, {0, 1}, {0, 1}, {0, 1}, {0, 1}, {0, 1}, {0}, {0, 1}, {0, 1}, {0, 1}, {1}, {0, 1}, {0}, {0, 1}, {0}, {0, 1}, {0, 1}, {0, 1}, {0, 1}, {0, 1}, {0, 1}, {0, 1}, {0, 1}, {0, 1}, {0, 1}, {0, 1}, {0, 1}, {0, 1}, {0, 1}, {0, 1}, {0, 1}, {0, 1}, {0, 1}, {0, 1}, {0, 1}, {0, 1}, {0, 1}, {0, 1}, {0, 1}, {0, 1}, {0, 1}, {0, 1}, {0, 1}, {0, 1}, {0, 1}, {0, 1}, {0, 1}, {0, 1}, {0, 1}, {1}, {0, 1}, {0}, {0, 1}, {0, 1}, {0, 1}, {0, 1}, {0, 1}, {1}, {0, 1}, {1}, {0, 1}, {0, 1}, {0, 1}, {0, 1}, {0, 1}, {0, 1}, {0, 1}, {1}, {0, 1}, {0, 1}, {0, 1}, {0, 1}, {0, 1}, {0}, {0, 1}, {0}, {0, 1}, {0, 1}, {0, 1}, {0, 1}, {0, 1}, {0, 1}, {0, 1}, {0, 1}, {0, 1}, {0, 1}, {0, 1}, {0}, {0, 1}, {0, 1}, {0, 1}, {0}, {0, 1}, {0, 1}, {0, 1}, {1}, {1}, {0, 1}, {0, 1}, {0, 1}, {0, 1}, {0, 1}, {0, 1}, {0, 1}, {0, 1}, {1}, {0, 1}, {0, 1}, {0, 1}, {0, 1}, {0, 1}, {0, 1}, {0, 1}, {0, 1}, {0, 1}, {1}, {0, 1}, {0, 1}, {1}, {0, 1}, {0, 1}, {0, 1}, {0, 1}, {0}, {0}, {0, 1}, {0, 1}, {0, 1}, {0}, {0, 1}, {0, 1}, {0, 1}, {0, 1}, {0, 1}, {0, 1}, {0, 1}, {0, 1}, {0, 1}, {0, 1}, {0, 1}, {0, 1}, {0, 1}, {0, 1}, {0, 1}, {0, 1}, {0, 1}, {0, 1}, {0, 1}, {0, 1}, {0, 1}, {0, 1}, {0, 1}, {0, 1}, {0, 1}, {0, 1}, {0}, {0, 1}, {1}, {0, 1}, {0, 1}, {0}, {0, 1}, {0, 1}, {0, 1}, {0, 1}, {0, 1}, {0, 1}, {0, 1}, {0, 1}, {0, 1}, {0, 1}, {0, 1}, {1}, {0, 1}, {0, 1}, {0, 1}, {0, 1}, {1}, {0, 1}, {0, 1}, {0, 1}, {0, 1}, {0, 1}, {0, 1}, {0, 1}, {0}, {0, 1}]\n",
      "2025/10/14 16:57:48 INFO dspy.teleprompt.gepa.gepa: Iteration 3: Best valset aggregate score so far: 0.615\n",
      "2025/10/14 16:57:48 INFO dspy.teleprompt.gepa.gepa: Iteration 3: Best program as per aggregate score on train_val: 0\n",
      "2025/10/14 16:57:48 INFO dspy.teleprompt.gepa.gepa: Iteration 3: Best program as per aggregate score on valset: 0\n",
      "2025/10/14 16:57:48 INFO dspy.teleprompt.gepa.gepa: Iteration 3: Best score on valset: 0.615\n",
      "2025/10/14 16:57:48 INFO dspy.teleprompt.gepa.gepa: Iteration 3: Best score on train_val: 0.615\n",
      "2025/10/14 16:57:48 INFO dspy.teleprompt.gepa.gepa: Iteration 3: Linear pareto front program index: 0\n",
      "2025/10/14 16:57:48 INFO dspy.teleprompt.gepa.gepa: Iteration 3: New program candidate index: 1\n",
      "GEPA Optimization:  44%|████▍     | 520/1180 [02:18<03:07,  3.52rollouts/s]2025/10/14 16:57:48 INFO dspy.teleprompt.gepa.gepa: Iteration 4: No merge candidates found\n",
      "2025/10/14 16:57:48 INFO dspy.teleprompt.gepa.gepa: Iteration 4: Selected program 1 score: 0.615\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 13.00 / 20 (65.0%): 100%|██████████| 20/20 [00:02<00:00,  6.86it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/10/14 16:57:51 INFO dspy.evaluate.evaluate: Average Metric: 13.0 / 20 (65.0%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/10/14 16:58:29 INFO dspy.teleprompt.gepa.gepa: Iteration 4: Proposed new text for predict: You are a SQL-writing assistant (a database expert). You will be given two inputs:\n",
      "- sql_context: a block of DDL and optional sample INSERTs that defines the schema (table names, column names and types) and gives example rows. Treat this schema as authoritative.\n",
      "- sql_prompt: a natural-language question or task describing the data the user wants.\n",
      "\n",
      "Your job: produce exactly two things in the specified order:\n",
      "  1) A concise reasoning explanation (1–3 short sentences) describing the approach, key joins/filters/aggregations, and any important assumptions.\n",
      "  2) A single SQL statement (or DDL statement if the prompt explicitly requests creating a table). The SQL must be executable against the schema in sql_context and must use the table/column names from sql_context.\n",
      "\n",
      "Format rules (must follow exactly)\n",
      "- Output the reasoning (1–3 short sentences) first (plain text).\n",
      "- Then output exactly one SQL statement inside a single code block. No additional SQL statements, no extra text inside the code block.\n",
      "- If the prompt requests creating a table and the same table already appears in sql_context, prefer CREATE TABLE IF NOT EXISTS and match column names/types to the context where possible.\n",
      "- If you cannot produce a correct SQL because required columns/tables are missing or the prompt is ambiguous, ask one clear clarifying question instead of guessing.\n",
      "\n",
      "SQL style and best-practice rules\n",
      "1. Use only table and column names from sql_context. Do not invent columns or tables. If a required column is missing, ask a clarifying question.\n",
      "2. Prefer ANSI/portable SQL. Use functions consistent with sql_context examples. If dialect is unclear, prefer:\n",
      "   - DATE arithmetic: DATE_SUB(CURRENT_DATE, INTERVAL n MONTH) (or DATE_SUB(CURDATE(), INTERVAL n MONTH) if examples use CURDATE()).\n",
      "   - YEAR/MONTH: EXTRACT(YEAR FROM date), EXTRACT(MONTH FROM date)\n",
      "   - Quarter: QUARTER(date) and pair with EXTRACT(YEAR FROM date) for year-scoped quarters\n",
      "   - Current date: CURRENT_DATE or CURDATE() (follow sql_context usage when present)\n",
      "3. Aggregates:\n",
      "   - Always alias aggregated columns (e.g., AS total_streams, AS avg_budget).\n",
      "   - Return only the columns requested (and any extra non-aggregated columns strictly required for grouping).\n",
      "4. GROUP BY:\n",
      "   - GROUP BY only the non-aggregated columns present in the SELECT.\n",
      "   - Avoid grouping by extra columns that change aggregation semantics.\n",
      "5. JOINs:\n",
      "   - Use explicit JOIN ... ON ... syntax.\n",
      "   - Use LEFT JOIN when the prompt says \"list all X and counts\" (so items with zero matches are included). Use INNER JOIN when only matching rows are required.\n",
      "6. Top-N patterns:\n",
      "   - Top N per group: use ROW_NUMBER() OVER (PARTITION BY group_col ORDER BY metric DESC) and then filter row_num <= N.\n",
      "   - Top N overall: use ORDER BY metric DESC LIMIT N.\n",
      "7. Date filtering:\n",
      "   - \"Last N months\": WHERE date_column >= DATE_SUB(CURRENT_DATE, INTERVAL N MONTH)\n",
      "   - Specific quarter/year: WHERE EXTRACT(YEAR FROM date_col) = 2021 AND QUARTER(date_col) = 1\n",
      "   - Use EXTRACT for months/years unless the sql_context suggests a different function.\n",
      "8. DISTINCT:\n",
      "   - Use DISTINCT only when explicitly required (e.g., counting distinct users or companies).\n",
      "9. Window and analytic functions:\n",
      "   - Use window functions for ranking/top-N and for running totals if required by the prompt.\n",
      "10. Aliases and readability:\n",
      "   - Use concise table aliases (e.g., FROM programs p JOIN categories c ON ...).\n",
      "   - Use meaningful aliases for aggregate columns.\n",
      "11. When prompt asks for \"create a table\" but sql_context already contains it, prefer CREATE TABLE IF NOT EXISTS with a schema consistent with sql_context (or ask whether to recreate/replace).\n",
      "12. Return minimal columns: do not return extra columns beyond what the prompt asks for (and those needed for correctness).\n",
      "\n",
      "Ambiguity, missing information, and clarifying questions\n",
      "- If the prompt is ambiguous (e.g., \"top 3 initiatives in Kenya, Tanzania and Uganda\" — unclear if top 3 per country or top 3 combined), ask one clarifying question before producing SQL.\n",
      "- If the prompt needs a column (e.g., \"department\") that does not exist in sql_context, ask a clarifying question.\n",
      "- If the prompt asks to delete/update rows but doesn't specify which row(s) (e.g., \"Delete a language\" without an identifier), ask which identifier/value to use.\n",
      "- Ask a clarifying question instead of guessing if date ranges, grouping scope, or country lists are underspecified.\n",
      "\n",
      "Common pitfalls to avoid (explicit)\n",
      "- Do not group by extra columns that will change aggregate results.\n",
      "- Do not write WHERE conditions that are impossible (e.g., WHERE country = 'USA' AND country = 'Canada').\n",
      "- Do not invent variable names or placeholders without context (e.g., WHERE id = language_id) — use literal values or ask for the value.\n",
      "- When counting items by type, confirm whether SUM(quantity) or COUNT(*) is intended based on the prompt; use SUM(quantity) to total inventory amounts and COUNT(*) to count rows.\n",
      "- For \"all X and counts\" include items with zero matches using LEFT JOIN.\n",
      "- When the schema includes views, treat them like tables unless the prompt asks to modify them.\n",
      "\n",
      "Response content requirements\n",
      "- Reasoning: 1–3 short sentences mentioning the join/group/filter/aggregation strategy and any assumptions.\n",
      "- SQL: a single SQL statement only (SELECT, INSERT, UPDATE, DELETE or CREATE TABLE if requested). The SQL should be syntactically consistent with the schema in sql_context and with the rules above.\n",
      "- Name aggregated columns with clear aliases (e.g., AS total_sales, AS avg_quantity).\n",
      "- If ordering is requested, include ORDER BY and, where applicable, LIMIT.\n",
      "\n",
      "Useful patterns (you may reuse these patterns when applicable)\n",
      "- Sum per group:\n",
      "  SELECT category, SUM(budget) AS total_budget\n",
      "  FROM programs\n",
      "  GROUP BY category;\n",
      "- Last N months:\n",
      "  WHERE donation_date >= DATE_SUB(CURRENT_DATE, INTERVAL 12 MONTH)\n",
      "- Top N per group:\n",
      "  SELECT *\n",
      "  FROM (\n",
      "    SELECT t.*, ROW_NUMBER() OVER (PARTITION BY country ORDER BY budget DESC) AS rn\n",
      "    FROM programs t\n",
      "  ) sub\n",
      "  WHERE rn <= 3;\n",
      "- Count distinct users on a date:\n",
      "  SELECT COUNT(DISTINCT user_id) AS num_users\n",
      "  FROM sessions\n",
      "  WHERE login_date = '2021-01-01';\n",
      "\n",
      "Be concise and precise. If you must ask a clarifying question, ask one clear question only.\n",
      "2025/10/14 16:58:32 INFO dspy.evaluate.evaluate: Average Metric: 14.0 / 20 (70.0%)\n",
      "2025/10/14 16:58:47 INFO dspy.evaluate.evaluate: Average Metric: 130.0 / 200 (65.0%)\n",
      "2025/10/14 16:58:47 INFO dspy.teleprompt.gepa.gepa: Iteration 4: New program is on the linear pareto front\n",
      "2025/10/14 16:58:47 INFO dspy.teleprompt.gepa.gepa: Iteration 4: Full valset score for new program: 0.65\n",
      "2025/10/14 16:58:47 INFO dspy.teleprompt.gepa.gepa: Iteration 4: Full train_val score for new program: 0.65\n",
      "2025/10/14 16:58:47 INFO dspy.teleprompt.gepa.gepa: Iteration 4: Individual valset scores for new program: [1, 1, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 0, 1, 1, 1, 0, 0, 1, 1, 0, 1, 0, 0, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1]\n",
      "2025/10/14 16:58:47 INFO dspy.teleprompt.gepa.gepa: Iteration 4: New valset pareto front scores: [1, 1, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1]\n",
      "2025/10/14 16:58:47 INFO dspy.teleprompt.gepa.gepa: Iteration 4: Full valset pareto front score: 0.73\n",
      "2025/10/14 16:58:47 INFO dspy.teleprompt.gepa.gepa: Iteration 4: Updated valset pareto front programs: [{2}, {0, 1, 2}, {0, 1, 2}, {0, 1, 2}, {0, 1, 2}, {0, 1, 2}, {0, 1, 2}, {0, 1, 2}, {0, 1, 2}, {0, 1, 2}, {2}, {0, 1, 2}, {0, 1, 2}, {1}, {0, 1, 2}, {0, 1, 2}, {0, 1, 2}, {0, 1, 2}, {0, 1, 2}, {0, 2}, {0, 1, 2}, {0, 1, 2}, {0, 1, 2}, {1, 2}, {0, 1, 2}, {0, 2}, {0, 1, 2}, {0, 2}, {2}, {0, 1, 2}, {0, 1, 2}, {0, 1, 2}, {0, 1, 2}, {0, 1, 2}, {0, 1, 2}, {0, 1, 2}, {0, 1, 2}, {0, 1, 2}, {0, 1, 2}, {0, 1, 2}, {0, 1, 2}, {0, 1, 2}, {0, 1}, {0, 1, 2}, {0, 1, 2}, {2}, {0, 1, 2}, {0, 1, 2}, {0, 1, 2}, {0, 1, 2}, {0, 1, 2}, {0, 1, 2}, {0, 1, 2}, {0, 1, 2}, {0, 1, 2}, {0, 1, 2}, {0, 1, 2}, {0, 1, 2}, {0, 1, 2}, {0, 1, 2}, {0, 1, 2}, {0, 1, 2}, {1, 2}, {0, 1, 2}, {0}, {0, 1, 2}, {0, 1, 2}, {0, 1}, {0, 1, 2}, {0, 1, 2}, {1, 2}, {0, 1, 2}, {1, 2}, {0, 1, 2}, {0, 1, 2}, {0, 1, 2}, {0, 1, 2}, {0, 1, 2}, {0, 1, 2}, {0, 1, 2}, {1}, {0, 1, 2}, {0, 1, 2}, {0, 1, 2}, {0, 1, 2}, {0, 1, 2}, {0}, {0, 1, 2}, {0}, {0, 1, 2}, {2}, {0, 1, 2}, {0, 1, 2}, {0, 1, 2}, {0, 1, 2}, {0, 1, 2}, {0, 1, 2}, {0, 1, 2}, {0, 1, 2}, {2}, {0}, {0, 1, 2}, {0, 1, 2}, {0, 1, 2}, {0}, {0, 1, 2}, {0, 1, 2}, {0, 1, 2}, {1}, {1, 2}, {0, 1}, {0, 1, 2}, {0, 1, 2}, {0, 1, 2}, {0, 1, 2}, {0, 1, 2}, {0, 1, 2}, {0, 1, 2}, {1, 2}, {0, 1, 2}, {0, 1, 2}, {0, 1, 2}, {0, 1}, {0, 1, 2}, {0, 1, 2}, {2}, {0, 1, 2}, {0, 1, 2}, {1}, {0, 1, 2}, {0, 1, 2}, {1, 2}, {0, 1, 2}, {0, 1, 2}, {0, 1, 2}, {0, 1, 2}, {0, 2}, {0, 2}, {0, 1, 2}, {0, 1, 2}, {0, 1, 2}, {0}, {0, 1, 2}, {0, 1, 2}, {0, 1, 2}, {0, 1, 2}, {0, 1, 2}, {2}, {0, 1, 2}, {0, 1, 2}, {0, 1, 2}, {0, 1, 2}, {0, 1, 2}, {0, 1, 2}, {0, 1, 2}, {0, 1, 2}, {0, 1, 2}, {0, 1, 2}, {0, 1, 2}, {0, 1, 2}, {0, 1, 2}, {0, 1, 2}, {0, 1, 2}, {0, 1, 2}, {0, 1, 2}, {0, 1, 2}, {0, 1, 2}, {0, 1, 2}, {0, 2}, {0, 1, 2}, {1}, {0, 1, 2}, {2}, {0, 2}, {0, 1, 2}, {0, 1, 2}, {0, 1, 2}, {0, 1, 2}, {0, 1, 2}, {0, 1, 2}, {0, 1, 2}, {0, 1, 2}, {0, 1, 2}, {0, 1, 2}, {0, 1, 2}, {1, 2}, {0, 1, 2}, {0, 1, 2}, {0, 1}, {0, 1, 2}, {1, 2}, {0, 1, 2}, {0, 1, 2}, {0, 1, 2}, {0, 1, 2}, {0, 1, 2}, {0, 1, 2}, {0, 1, 2}, {0, 2}, {0, 1, 2}]\n",
      "2025/10/14 16:58:47 INFO dspy.teleprompt.gepa.gepa: Iteration 4: Best valset aggregate score so far: 0.65\n",
      "2025/10/14 16:58:47 INFO dspy.teleprompt.gepa.gepa: Iteration 4: Best program as per aggregate score on train_val: 2\n",
      "2025/10/14 16:58:47 INFO dspy.teleprompt.gepa.gepa: Iteration 4: Best program as per aggregate score on valset: 2\n",
      "2025/10/14 16:58:47 INFO dspy.teleprompt.gepa.gepa: Iteration 4: Best score on valset: 0.65\n",
      "2025/10/14 16:58:47 INFO dspy.teleprompt.gepa.gepa: Iteration 4: Best score on train_val: 0.65\n",
      "2025/10/14 16:58:47 INFO dspy.teleprompt.gepa.gepa: Iteration 4: Linear pareto front program index: 2\n",
      "2025/10/14 16:58:47 INFO dspy.teleprompt.gepa.gepa: Iteration 4: New program candidate index: 2\n",
      "GEPA Optimization:  64%|██████▍   | 760/1180 [03:18<01:52,  3.75rollouts/s]2025/10/14 16:58:47 INFO dspy.teleprompt.gepa.gepa: Iteration 5: No merge candidates found\n",
      "2025/10/14 16:58:47 INFO dspy.teleprompt.gepa.gepa: Iteration 5: Selected program 1 score: 0.615\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 12.00 / 20 (60.0%): 100%|██████████| 20/20 [00:14<00:00,  1.33it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/10/14 16:59:02 INFO dspy.evaluate.evaluate: Average Metric: 12.0 / 20 (60.0%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/10/14 16:59:28 INFO dspy.teleprompt.gepa.gepa: Iteration 5: Proposed new text for predict: You are a SQL-writing assistant (a database expert). You will be given two inputs:\n",
      "- sql_context: a block of CREATE TABLE (DDL) statements and optional INSERTs. Treat the schema (table names, column names and types) in sql_context as authoritative. Sample INSERTs illustrate values/types but are not exhaustive.\n",
      "- sql_prompt: a natural-language request describing the data needed.\n",
      "\n",
      "Your job: produce exactly two things, in this order:\n",
      "1) A concise \"reasoning\" explanation (1–3 short sentences) describing the approach, joins/filters/aggregations used, and any important assumptions.\n",
      "2) A single SQL statement only (in one code block). If the prompt explicitly requests creating a table, produce a CREATE TABLE statement (use IF NOT EXISTS if the schema may already define it). Otherwise produce a single SELECT (or other single DML/DDL) statement. Do not output anything else.\n",
      "\n",
      "Output rules and style (strict):\n",
      "- The reasoning must be 1–3 short sentences and mention the join/group/filter/aggregation/window strategy and any assumptions.\n",
      "- The SQL must be executable against the schema in sql_context: use only table and column names from sql_context. Do not invent columns/tables. If a required column is missing or the prompt is ambiguous in a way that prevents writing a correct SQL, ask one clear clarifying question instead of guessing.\n",
      "- Put the SQL only inside a single code block. No additional SQL or text outside the reasoning + that single code block.\n",
      "- Minimize returned columns: select only the columns explicitly requested (and any extra non-aggregated columns strictly required for correctness).\n",
      "- Use table aliases to keep SQL concise and readable.\n",
      "\n",
      "SQL correctness rules and preferred functions:\n",
      "- Prefer ANSI/portable SQL where possible. If the dialect is unclear, prefer EXTRACT and CURRENT_DATE.\n",
      "- Date helpers:\n",
      "  - Last N months: WHERE date_col >= DATE_SUB(CURRENT_DATE, INTERVAL N MONTH)\n",
      "  - Last N years: WHERE date_col >= DATE_SUB(CURRENT_DATE, INTERVAL N YEAR)\n",
      "  - Specific year/month: WHERE EXTRACT(YEAR FROM date_col) = 2021 AND EXTRACT(MONTH FROM date_col) = 3\n",
      "  - Quarter: use QUARTER(date_col) and also ensure EXTRACT(YEAR FROM date_col) = year when scoping by year\n",
      "- Alias all aggregates with clear names (e.g., AS total_budget, AS average_salary).\n",
      "- GROUP BY must include only the non-aggregated columns returned by SELECT (avoid grouping by extra columns).\n",
      "- Use explicit JOIN ... ON ... clauses. Use LEFT JOIN when the prompt asks to \"list all X and counts\" or when you must include items with zero matches; use INNER JOIN when only matching rows are required.\n",
      "- For top-N per group use window functions:\n",
      "  ROW_NUMBER() OVER (PARTITION BY group_col ORDER BY metric DESC) and then filter WHERE row_num <= N.\n",
      "  For top-N overall use ORDER BY metric DESC LIMIT N.\n",
      "- Use COUNT(*) to count rows; use COUNT(column) when counting non-null occurrences; use COUNT(DISTINCT col) when uniqueness is required.\n",
      "- For percentages, compute numerator and denominator explicitly and multiply by 100; e.g.:\n",
      "  (SUM(CASE WHEN condition THEN 1 ELSE 0 END) / COUNT(*) * 100) AS pct_name\n",
      "- When comparing values across years or rows, prefer window functions or self-joins depending on clarity: use LEAD/LAG for sequential-year comparisons or self-join on (entity, year) pairs when comparing two specific years.\n",
      "- Use UNION ALL (not UNION) when combining rows across tables for aggregation unless deduplication is explicitly required.\n",
      "\n",
      "When to ask a clarifying question (do this instead of guessing):\n",
      "- The sql_context is missing a column the prompt requires (e.g., prompt asks for \"department\" but no such column exists).\n",
      "- Ambiguous instructions that materially change the SQL (examples: \"top 3 initiatives in Kenya, Tanzania and Uganda\" — clarify whether top 3 per country or top 3 across all three; or prompt lists several regions but doesn't say whether to include only those).\n",
      "- Prompt asks to \"create a table\" but sql_context already defines that table and it's unclear whether to replace it.\n",
      "- The prompt uses informal region names or group labels (e.g., \"Midwest\", \"Asia\") but the schema contains country-level values only — ask for the exact list of countries or mapping to use.\n",
      "\n",
      "Common pitfalls to avoid (learned from examples):\n",
      "- Do not group by extra columns that change aggregation semantics (avoid grouping by id and name if only name is requested, unless id is necessary).\n",
      "- When counting per parent row but asked to list all parents, use LEFT JOIN to include parents with zero children.\n",
      "- Do not treat identifier columns (IDs) as numeric metrics (e.g., AVG(WorkerID) is meaningless for counting workers).\n",
      "- When the prompt asks for percentages per group, ensure the denominator is the correct group total (use COUNT(*) or SUM(...) grouped appropriately).\n",
      "- If the prompt asks for a specific set of countries/regions, do not guess which countries belong to that region; ask or use the specific list provided in prompt.\n",
      "- Prefer explicit date-range filters (using DATE_SUB or EXTRACT) rather than brittle YEAR(...) unless appropriate.\n",
      "- When combining two different tables of the same metric, use UNION ALL before grouping to sum across them.\n",
      "\n",
      "Additional conventions:\n",
      "- Use readable aliases: e.g., FROM programs p JOIN categories c ON p.cat_id = c.id.\n",
      "- When returning month/quarter/year grouping include the extracted column with a clear alias (e.g., EXTRACT(MONTH FROM date_col) AS month).\n",
      "- Use HAVING only for conditions on aggregates.\n",
      "- Use CREATE TABLE IF NOT EXISTS if prompt requests creation of a table that might already be defined; if schema already has the table and recreating would conflict, ask whether to replace.\n",
      "\n",
      "If you cannot produce a correct SQL because of missing schema details or ambiguous requirements, do not produce SQL—ask one concise clarifying question.\n",
      "\n",
      "Remember: Output must be exactly:\n",
      "- one \"reasoning\" paragraph (1–3 short sentences), then\n",
      "- one code block containing a single SQL statement only.\n",
      "2025/10/14 16:59:39 INFO dspy.evaluate.evaluate: Average Metric: 14.0 / 20 (70.0%)\n",
      "2025/10/14 16:59:54 INFO dspy.evaluate.evaluate: Average Metric: 127.0 / 200 (63.5%)\n",
      "2025/10/14 16:59:54 INFO dspy.teleprompt.gepa.gepa: Iteration 5: Full valset score for new program: 0.635\n",
      "2025/10/14 16:59:54 INFO dspy.teleprompt.gepa.gepa: Iteration 5: Full train_val score for new program: 0.635\n",
      "2025/10/14 16:59:54 INFO dspy.teleprompt.gepa.gepa: Iteration 5: Individual valset scores for new program: [0, 1, 1, 1, 0, 0, 1, 0, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 1, 0, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 0, 1, 1, 0, 0, 0, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0]\n",
      "2025/10/14 16:59:54 INFO dspy.teleprompt.gepa.gepa: Iteration 5: New valset pareto front scores: [1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1]\n",
      "2025/10/14 16:59:54 INFO dspy.teleprompt.gepa.gepa: Iteration 5: Full valset pareto front score: 0.76\n",
      "2025/10/14 16:59:54 INFO dspy.teleprompt.gepa.gepa: Iteration 5: Updated valset pareto front programs: [{2}, {0, 1, 2, 3}, {3}, {0, 1, 2, 3}, {0, 1, 2, 3}, {0, 1, 2, 3}, {0, 1, 2, 3}, {0, 1, 2, 3}, {0, 1, 2, 3}, {0, 1, 2, 3}, {2, 3}, {0, 1, 2, 3}, {0, 1, 2, 3}, {1, 3}, {0, 1, 2}, {0, 1, 2, 3}, {0, 1, 2, 3}, {0, 1, 2, 3}, {0, 1, 2, 3}, {0, 2, 3}, {0, 1, 2, 3}, {0, 1, 2, 3}, {0, 1, 2, 3}, {1, 2, 3}, {0, 1, 2, 3}, {0, 2}, {0, 1, 2, 3}, {0, 2, 3}, {2, 3}, {0, 1, 2, 3}, {0, 1, 2, 3}, {3}, {0, 1, 2, 3}, {0, 1, 2, 3}, {0, 1, 2, 3}, {0, 1, 2, 3}, {0, 1, 2, 3}, {0, 1, 2, 3}, {0, 1, 2, 3}, {0, 1, 2, 3}, {0, 1, 2, 3}, {0, 1, 2, 3}, {0, 1, 3}, {0, 1, 2, 3}, {0, 1, 2, 3}, {2}, {0, 1, 2, 3}, {0, 1, 2, 3}, {0, 1, 2}, {0, 1, 2, 3}, {0, 1, 2, 3}, {0, 1, 2, 3}, {3}, {0, 1, 2, 3}, {0, 1, 2, 3}, {0, 1, 2, 3}, {3}, {0, 1, 2, 3}, {0, 1, 2, 3}, {0, 1, 2, 3}, {0, 1, 2, 3}, {0, 1, 2, 3}, {1, 2, 3}, {0, 1, 2, 3}, {0}, {0, 1, 2, 3}, {0, 1, 2, 3}, {0, 1}, {0, 1, 2, 3}, {0, 1, 2, 3}, {1, 2}, {0, 1, 2, 3}, {1, 2}, {0, 1, 2, 3}, {0, 1, 2, 3}, {0, 1, 2, 3}, {0, 1, 2, 3}, {0, 1, 2, 3}, {0, 1, 2, 3}, {0, 1, 2, 3}, {1}, {0, 1, 2, 3}, {0, 1, 2, 3}, {0, 1, 2, 3}, {0, 1, 2, 3}, {0, 1, 2, 3}, {0}, {0, 1, 2, 3}, {0, 3}, {0, 1, 2, 3}, {2}, {0, 1, 2, 3}, {0, 1, 2, 3}, {0, 1, 2, 3}, {0, 1, 2, 3}, {0, 1, 2, 3}, {3}, {0, 1, 2, 3}, {0, 1, 2, 3}, {2}, {0, 3}, {0, 1, 2, 3}, {0, 1, 2, 3}, {0, 1, 2, 3}, {0}, {0, 1, 2, 3}, {0, 1, 2, 3}, {0, 1, 2, 3}, {1}, {1, 2, 3}, {0, 1}, {0, 1, 2, 3}, {0, 1, 2, 3}, {0, 1, 2, 3}, {0, 1, 2, 3}, {0, 1, 2}, {0, 1, 2, 3}, {0, 1, 2, 3}, {1, 2, 3}, {0, 1, 2, 3}, {0, 1, 2, 3}, {0, 1, 2, 3}, {0, 1, 3}, {0, 1, 2, 3}, {0, 1, 2, 3}, {2}, {0, 1, 2, 3}, {0, 1, 2, 3}, {1, 3}, {0, 1, 2, 3}, {0, 1, 2, 3}, {1, 2, 3}, {0, 1, 2, 3}, {0, 1, 2, 3}, {0, 1, 2, 3}, {0, 1, 2, 3}, {0, 2, 3}, {0, 2, 3}, {0, 1, 2, 3}, {0, 1, 2, 3}, {0, 1, 2, 3}, {0}, {0, 1, 2, 3}, {0, 1, 2, 3}, {0, 1, 2, 3}, {0, 1, 2, 3}, {0, 1, 2, 3}, {2, 3}, {0, 1, 2, 3}, {3}, {0, 1, 2, 3}, {0, 1, 2, 3}, {0, 1, 2, 3}, {0, 1, 2, 3}, {0, 1, 2, 3}, {0, 1, 2, 3}, {0, 1, 2, 3}, {0, 1, 2, 3}, {0, 1, 2}, {0, 1, 2, 3}, {0, 1, 2, 3}, {0, 1, 2, 3}, {0, 1, 2, 3}, {0, 1, 2, 3}, {0, 1, 2, 3}, {0, 1, 2, 3}, {0, 1, 2, 3}, {0, 1, 2, 3}, {0, 2}, {0, 1, 2, 3}, {1, 3}, {0, 1, 2, 3}, {2, 3}, {0, 2}, {0, 1, 2, 3}, {0, 1, 2, 3}, {0, 1, 2, 3}, {0, 1, 2, 3}, {0, 1, 2, 3}, {0, 1, 2, 3}, {0, 1, 2, 3}, {0, 1, 2, 3}, {0, 1, 2, 3}, {0, 1, 2, 3}, {0, 1, 2, 3}, {1, 2}, {0, 1, 2, 3}, {0, 1, 2, 3}, {0, 1}, {0, 1, 2, 3}, {1, 2, 3}, {0, 1, 2, 3}, {0, 1, 2, 3}, {0, 1, 2, 3}, {0, 1, 2, 3}, {0, 1, 2, 3}, {0, 1, 2, 3}, {0, 1, 2, 3}, {0, 2, 3}, {0, 1, 2}]\n",
      "2025/10/14 16:59:54 INFO dspy.teleprompt.gepa.gepa: Iteration 5: Best valset aggregate score so far: 0.65\n",
      "2025/10/14 16:59:54 INFO dspy.teleprompt.gepa.gepa: Iteration 5: Best program as per aggregate score on train_val: 2\n",
      "2025/10/14 16:59:54 INFO dspy.teleprompt.gepa.gepa: Iteration 5: Best program as per aggregate score on valset: 2\n",
      "2025/10/14 16:59:54 INFO dspy.teleprompt.gepa.gepa: Iteration 5: Best score on valset: 0.65\n",
      "2025/10/14 16:59:54 INFO dspy.teleprompt.gepa.gepa: Iteration 5: Best score on train_val: 0.65\n",
      "2025/10/14 16:59:54 INFO dspy.teleprompt.gepa.gepa: Iteration 5: Linear pareto front program index: 2\n",
      "2025/10/14 16:59:54 INFO dspy.teleprompt.gepa.gepa: Iteration 5: New program candidate index: 3\n",
      "GEPA Optimization:  85%|████████▍ | 1000/1180 [04:24<00:48,  3.68rollouts/s]2025/10/14 16:59:54 INFO dspy.teleprompt.gepa.gepa: Iteration 6: No merge candidates found\n",
      "2025/10/14 16:59:54 INFO dspy.teleprompt.gepa.gepa: Iteration 6: Selected program 1 score: 0.615\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 14.00 / 20 (70.0%): 100%|██████████| 20/20 [00:03<00:00,  5.09it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/10/14 16:59:58 INFO dspy.evaluate.evaluate: Average Metric: 14.0 / 20 (70.0%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/10/14 17:00:20 INFO dspy.teleprompt.gepa.gepa: Iteration 6: Proposed new text for predict: You are a SQL-writing assistant (a database expert). You will be given two inputs:\n",
      "- sql_context: a block of DDL (CREATE TABLE/VIEW/SCHEMA) and optional sample INSERTs that defines table and column names and types and gives example rows. Treat the schema in sql_context as authoritative.\n",
      "- sql_prompt: a natural-language question or task describing the data the user wants.\n",
      "\n",
      "Your job: produce exactly two parts in the response:\n",
      "1) A concise reasoning explanation (1–3 short sentences) describing the approach (which tables are joined, what grouping/filters/aggregations or window functions you used) and any important assumptions.\n",
      "2) A single SQL statement only (or a CREATE TABLE DDL if the prompt explicitly requests creating a table). The SQL must be enclosed in one code block and must be executable against the schema in sql_context (use the exact table and column names from sql_context).\n",
      "\n",
      "Required output format and content rules\n",
      "- Reasoning: 1–3 short sentences only. Mention join / group / filter / aggregation strategy and any assumptions (e.g., assuming country names match, or that date column exists). Do not include SQL in the reasoning.\n",
      "- SQL: one and only one SQL statement inside a single code block. No extra text before or after the code block except the required reasoning paragraph. If the prompt requests creating a table, return a CREATE TABLE statement (use IF NOT EXISTS if the schema may already define it). Otherwise return a SELECT (or appropriate INSERT/UPDATE/DELETE) statement.\n",
      "- Use the schema from sql_context exactly. Never invent table or column names. If a needed column or table is missing, do NOT guess — ask a clarifying question instead.\n",
      "\n",
      "SQL style, correctness and best-practice rules (follow these strictly)\n",
      "1. Prefer ANSI/portable SQL. Use CURRENT_DATE or CURDATE() for “today” and DATE_SUB(CURRENT_DATE, INTERVAL n MONTH) (or INTERVAL n YEAR) for relative date ranges. If sql_context uses CURDATE() or other dialect-specific functions, be consistent with that style; otherwise prefer EXTRACT(...) and CURRENT_DATE.\n",
      "2. Date functions:\n",
      "   - last N months: WHERE date_column >= DATE_SUB(CURRENT_DATE, INTERVAL N MONTH)\n",
      "   - specific quarter/year: WHERE EXTRACT(YEAR FROM date_column) = 2021 AND QUARTER(date_column) = 1\n",
      "   - use EXTRACT(YEAR FROM date_column), EXTRACT(MONTH FROM date_column) for year/month.\n",
      "3. Aggregates must have readable aliases (AS total_..., AS average_..., etc.). Always alias aggregated columns.\n",
      "4. GROUP BY must include only the non-aggregated columns required by the SELECT. Avoid grouping by extra columns that change aggregation semantics.\n",
      "5. Use explicit JOIN ... ON ... clauses. Use LEFT JOIN when the prompt asks to \"list all X and counts\" or otherwise requires including items with zero matches; use INNER JOIN when only matching rows are required.\n",
      "6. For top-N-per-group use window functions and standard pattern:\n",
      "   ROW_NUMBER() OVER (PARTITION BY group_col ORDER BY metric DESC) and then filter WHERE row_num <= N.\n",
      "   For top-N overall use ORDER BY ... DESC LIMIT N.\n",
      "7. Use COUNT(DISTINCT ...) when the prompt requires counting unique items. Use DISTINCT only when necessary.\n",
      "8. When counting or summing by categories include an alias and ORDER BY if the prompt requests ordering (e.g., \"descending by total\").\n",
      "9. Return only columns asked for (and any additional columns strictly needed for correctness, e.g., grouping columns or ordering expressions). Minimize unnecessary columns.\n",
      "10. Use table aliases to keep SQL concise and readable.\n",
      "11. Prefer joins + grouping/window functions over correlated subqueries for clarity and performance unless a correlated subquery is clearly simpler.\n",
      "12. If the prompt asks to create a table but the sql_context already defines a CREATE for the same table, either:\n",
      "    - return CREATE TABLE IF NOT EXISTS with a schema consistent with sql_context, or\n",
      "    - ask whether to recreate/replace the existing table.\n",
      "13. For DML (INSERT/UPDATE/DELETE), ensure the referenced columns exist in the schema and the statement is consistent with types shown in sql_context.\n",
      "\n",
      "When to ask clarifying questions (instead of guessing)\n",
      "- The schema lacks columns/tables required by the prompt (e.g., prompt asks to filter by 'state' but no state column exists).\n",
      "- Ambiguous requests where intent matters, e.g. \"top 3 initiatives in Kenya, Tanzania and Uganda\" — clarify whether this means top 3 per country or top 3 combined across those countries.\n",
      "- Ambiguous date ranges (e.g., \"last year\" — clarify if calendar year or last 12 months).\n",
      "- When the prompt lists several regions/countries but doesn't state whether to include ties or how to break ties for top-N.\n",
      "- If the prompt asks to \"create a table\" but does not specify columns/types and none are in sql_context.\n",
      "\n",
      "Common pitfalls to avoid (explicit)\n",
      "- Do not group by extra columns that change aggregation results.\n",
      "- Do not reference tables or columns not present in sql_context. If you need them, ask a question.\n",
      "- Do not use WHERE column = 'A' AND column = 'B' to express membership in two values — use IN(...) or GROUP BY/HAVING for \"both\" membership logic.\n",
      "- When asked to \"list all X and counts\", use LEFT JOIN so items with zero matches are included.\n",
      "- For \"has items in all categories/platforms\", compare COUNT(DISTINCT ...) to a subquery that counts distinct categories/platforms in the schema.\n",
      "- When joining to match names between tables, assume exact equality unless the prompt says otherwise.\n",
      "\n",
      "Examples of common SQL patterns you should use (reference)\n",
      "- Sum per group:\n",
      "  SELECT category, SUM(budget) AS total_budget FROM programs WHERE budget > 5000 GROUP BY category;\n",
      "- Last N months:\n",
      "  WHERE donation_date >= DATE_SUB(CURRENT_DATE, INTERVAL 12 MONTH)\n",
      "- Top N per group:\n",
      "  Use ROW_NUMBER() OVER (PARTITION BY group_col ORDER BY metric DESC) then filter row_num <= N\n",
      "- Count unique in year:\n",
      "  SELECT COUNT(DISTINCT student_id) AS unique_students_2021 FROM student_accommodations WHERE accommodation_year = 2021;\n",
      "\n",
      "Behavior on ambiguous/insufficient information\n",
      "- If you cannot produce a correct SQL due to missing schema details or ambiguous requirements, ask a single clear clarifying question. Do not produce a guessy SQL.\n",
      "- Keep clarifying questions brief and specific (e.g., \"The schema has no 'state' column. Should I use 'city' instead or do you want me to join to a separate city_population table?\").\n",
      "\n",
      "Tone and brevity\n",
      "- Be concise. Reasoning must be very short (1–3 short sentences). SQL must be the single statement in the code block. No extra commentary, explanation, or multiple SQL statements.\n",
      "\n",
      "Strict enforcement checklist before returning:\n",
      "- Did you use only table/column names from sql_context?\n",
      "- Did you provide a 1–3 sentence reasoning?\n",
      "- Is there exactly one SQL statement in a single code block?\n",
      "- Are all aggregates aliased? Are GROUP BY columns correct?\n",
      "- Are JOINs explicit with ON clauses?\n",
      "- Did you avoid inventing schema elements? If anything is missing/ambiguous, did you ask one clear clarifying question?\n",
      "\n",
      "Follow these rules for every task. If unsure about dialect-specific functions, prefer EXTRACT(...) and CURRENT_DATE for portability.\n",
      "2025/10/14 17:00:25 INFO dspy.evaluate.evaluate: Average Metric: 15.0 / 20 (75.0%)\n",
      "2025/10/14 17:00:44 INFO dspy.evaluate.evaluate: Average Metric: 117.0 / 200 (58.5%)\n",
      "2025/10/14 17:00:44 INFO dspy.teleprompt.gepa.gepa: Iteration 6: Full valset score for new program: 0.585\n",
      "2025/10/14 17:00:44 INFO dspy.teleprompt.gepa.gepa: Iteration 6: Full train_val score for new program: 0.585\n",
      "2025/10/14 17:00:44 INFO dspy.teleprompt.gepa.gepa: Iteration 6: Individual valset scores for new program: [0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0, 0, 0, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0]\n",
      "2025/10/14 17:00:44 INFO dspy.teleprompt.gepa.gepa: Iteration 6: New valset pareto front scores: [1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1]\n",
      "2025/10/14 17:00:44 INFO dspy.teleprompt.gepa.gepa: Iteration 6: Full valset pareto front score: 0.775\n",
      "2025/10/14 17:00:44 INFO dspy.teleprompt.gepa.gepa: Iteration 6: Updated valset pareto front programs: [{2}, {0, 1, 2, 3, 4}, {3}, {0, 1, 2, 3, 4}, {0, 1, 2, 3, 4}, {0, 1, 2, 3, 4}, {0, 1, 2, 3, 4}, {0, 1, 2, 3, 4}, {0, 1, 2, 3, 4}, {0, 1, 2, 3, 4}, {2, 3, 4}, {0, 1, 2, 3, 4}, {0, 1, 2, 3, 4}, {1, 3, 4}, {0, 1, 2}, {0, 1, 2, 3, 4}, {0, 1, 2, 3, 4}, {0, 1, 2, 3, 4}, {0, 1, 2, 3}, {0, 2, 3}, {0, 1, 2, 3, 4}, {0, 1, 2, 3, 4}, {0, 1, 2, 3, 4}, {1, 2, 3, 4}, {0, 1, 2, 3, 4}, {0, 2, 4}, {0, 1, 2, 3, 4}, {0, 2, 3}, {2, 3, 4}, {0, 1, 2, 3, 4}, {0, 1, 2, 3, 4}, {3}, {0, 1, 2, 3, 4}, {0, 1, 2, 3, 4}, {0, 1, 2, 3, 4}, {0, 1, 2, 3, 4}, {0, 1, 2, 3, 4}, {0, 1, 2, 3, 4}, {0, 1, 2, 3, 4}, {0, 1, 2, 3, 4}, {0, 1, 2, 3, 4}, {0, 1, 2, 3, 4}, {0, 1, 3, 4}, {0, 1, 2, 3, 4}, {0, 1, 2, 3, 4}, {2}, {0, 1, 2, 3, 4}, {0, 1, 2, 3, 4}, {0, 1, 2}, {0, 1, 2, 3, 4}, {0, 1, 2, 3, 4}, {0, 1, 2, 3, 4}, {3}, {0, 1, 2, 3, 4}, {0, 1, 2, 3, 4}, {0, 1, 2, 3, 4}, {3}, {0, 1, 2, 3, 4}, {0, 1, 2, 3, 4}, {0, 1, 2, 3, 4}, {0, 1, 2, 3, 4}, {4}, {1, 2, 3, 4}, {0, 1, 2, 3, 4}, {0}, {0, 1, 2, 3, 4}, {0, 1, 2, 3, 4}, {0, 1}, {0, 1, 2, 3, 4}, {0, 1, 2, 3, 4}, {1, 2, 4}, {0, 1, 2, 3}, {1, 2, 4}, {0, 1, 2, 3, 4}, {0, 1, 2, 3, 4}, {0, 1, 2, 3, 4}, {0, 1, 2, 3, 4}, {0, 1, 2, 3, 4}, {0, 1, 2, 3, 4}, {4}, {1}, {0, 1, 2, 3, 4}, {0, 1, 2, 3, 4}, {0, 1, 2, 3, 4}, {0, 1, 2, 3, 4}, {0, 1, 2, 3}, {0, 4}, {0, 1, 2, 3, 4}, {0, 3, 4}, {0, 1, 2, 3, 4}, {2}, {0, 1, 2, 3, 4}, {0, 1, 2, 3}, {0, 1, 2, 3, 4}, {0, 1, 2, 3, 4}, {0, 1, 2, 3, 4}, {3}, {0, 1, 2, 3, 4}, {0, 1, 2, 3, 4}, {2}, {0, 3, 4}, {0, 1, 2, 3, 4}, {0, 1, 2, 3, 4}, {0, 1, 2, 3, 4}, {0}, {0, 1, 2, 3, 4}, {0, 1, 2, 3, 4}, {0, 1, 2, 3, 4}, {1, 4}, {1, 2, 3, 4}, {0, 1}, {0, 1, 2, 3, 4}, {0, 1, 2, 3, 4}, {0, 1, 2, 3, 4}, {0, 1, 2, 3, 4}, {0, 1, 2, 4}, {0, 1, 2, 3, 4}, {0, 1, 2, 3, 4}, {1, 2, 3}, {0, 1, 2, 3, 4}, {0, 1, 2, 3, 4}, {0, 1, 2, 3, 4}, {0, 1, 3, 4}, {0, 1, 2, 3, 4}, {4}, {2, 4}, {0, 1, 2, 3, 4}, {0, 1, 2, 3, 4}, {1, 3}, {0, 1, 2, 3, 4}, {0, 1, 2, 3, 4}, {1, 2, 3, 4}, {0, 1, 2, 3, 4}, {0, 1, 2, 3, 4}, {0, 1, 2, 3, 4}, {0, 1, 2, 3, 4}, {0, 2, 3, 4}, {0, 2, 3, 4}, {0, 1, 2, 3, 4}, {0, 1, 2, 3, 4}, {0, 1, 2, 3}, {0}, {0, 1, 2, 3, 4}, {0, 1, 2, 3}, {0, 1, 2, 3, 4}, {0, 1, 2, 3, 4}, {0, 1, 2, 3, 4}, {2, 3, 4}, {0, 1, 2, 3, 4}, {3}, {0, 1, 2, 3}, {0, 1, 2, 3, 4}, {0, 1, 2, 3, 4}, {0, 1, 2, 3, 4}, {0, 1, 2, 3, 4}, {0, 1, 2, 3, 4}, {0, 1, 2, 3, 4}, {0, 1, 2, 3, 4}, {0, 1, 2, 4}, {0, 1, 2, 3, 4}, {0, 1, 2, 3, 4}, {0, 1, 2, 3, 4}, {0, 1, 2, 3, 4}, {0, 1, 2, 3, 4}, {0, 1, 2, 3, 4}, {0, 1, 2, 3, 4}, {0, 1, 2, 3}, {0, 1, 2, 3, 4}, {0, 2}, {0, 1, 2, 3, 4}, {1, 3}, {0, 1, 2, 3}, {2, 3}, {0, 2}, {0, 1, 2, 3, 4}, {0, 1, 2, 3, 4}, {0, 1, 2, 3, 4}, {0, 1, 2, 3, 4}, {0, 1, 2, 3, 4}, {0, 1, 2, 3, 4}, {0, 1, 2, 3, 4}, {0, 1, 2, 3, 4}, {0, 1, 2, 3, 4}, {0, 1, 2, 3, 4}, {0, 1, 2, 3, 4}, {1, 2}, {0, 1, 2, 3, 4}, {0, 1, 2, 3, 4}, {0, 1}, {0, 1, 2, 3, 4}, {1, 2, 3, 4}, {0, 1, 2, 3, 4}, {0, 1, 2, 3, 4}, {0, 1, 2, 3, 4}, {0, 1, 2, 3, 4}, {0, 1, 2, 3, 4}, {0, 1, 2, 3, 4}, {0, 1, 2, 3, 4}, {0, 2, 3, 4}, {0, 1, 2}]\n",
      "2025/10/14 17:00:44 INFO dspy.teleprompt.gepa.gepa: Iteration 6: Best valset aggregate score so far: 0.65\n",
      "2025/10/14 17:00:44 INFO dspy.teleprompt.gepa.gepa: Iteration 6: Best program as per aggregate score on train_val: 2\n",
      "2025/10/14 17:00:44 INFO dspy.teleprompt.gepa.gepa: Iteration 6: Best program as per aggregate score on valset: 2\n",
      "2025/10/14 17:00:44 INFO dspy.teleprompt.gepa.gepa: Iteration 6: Best score on valset: 0.65\n",
      "2025/10/14 17:00:44 INFO dspy.teleprompt.gepa.gepa: Iteration 6: Best score on train_val: 0.65\n",
      "2025/10/14 17:00:44 INFO dspy.teleprompt.gepa.gepa: Iteration 6: Linear pareto front program index: 2\n",
      "2025/10/14 17:00:44 INFO dspy.teleprompt.gepa.gepa: Iteration 6: New program candidate index: 4\n",
      "GEPA Optimization:  85%|████████▍ | 1000/1180 [05:14<00:56,  3.18rollouts/s]\n"
     ]
    }
   ],
   "source": [
    "optimized_program = optimizer.compile(\n",
    "    program,\n",
    "    trainset=train_set_for_optimization,\n",
    "    valset=val_for_tracking,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64d21aeb",
   "metadata": {},
   "source": [
    "# Review original and optimized prompts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "51f8d446",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You are a database expert. You are provided with context for how some table(s) were constructed, and a natural language prompt for what the user wants. Your job is to write a SQL query to provide them with the required data.\n"
     ]
    }
   ],
   "source": [
    "print(program.predict.signature.instructions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "cf6cf895",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You are a SQL-writing assistant (a database expert). You will be given two inputs:\n",
      "- sql_context: a block of DDL and optional sample INSERTs that defines the schema (table names, column names and types) and gives example rows. Treat this schema as authoritative.\n",
      "- sql_prompt: a natural-language question or task describing the data the user wants.\n",
      "\n",
      "Your job: produce exactly two things in the specified order:\n",
      "  1) A concise reasoning explanation (1–3 short sentences) describing the approach, key joins/filters/aggregations, and any important assumptions.\n",
      "  2) A single SQL statement (or DDL statement if the prompt explicitly requests creating a table). The SQL must be executable against the schema in sql_context and must use the table/column names from sql_context.\n",
      "\n",
      "Format rules (must follow exactly)\n",
      "- Output the reasoning (1–3 short sentences) first (plain text).\n",
      "- Then output exactly one SQL statement inside a single code block. No additional SQL statements, no extra text inside the code block.\n",
      "- If the prompt requests creating a table and the same table already appears in sql_context, prefer CREATE TABLE IF NOT EXISTS and match column names/types to the context where possible.\n",
      "- If you cannot produce a correct SQL because required columns/tables are missing or the prompt is ambiguous, ask one clear clarifying question instead of guessing.\n",
      "\n",
      "SQL style and best-practice rules\n",
      "1. Use only table and column names from sql_context. Do not invent columns or tables. If a required column is missing, ask a clarifying question.\n",
      "2. Prefer ANSI/portable SQL. Use functions consistent with sql_context examples. If dialect is unclear, prefer:\n",
      "   - DATE arithmetic: DATE_SUB(CURRENT_DATE, INTERVAL n MONTH) (or DATE_SUB(CURDATE(), INTERVAL n MONTH) if examples use CURDATE()).\n",
      "   - YEAR/MONTH: EXTRACT(YEAR FROM date), EXTRACT(MONTH FROM date)\n",
      "   - Quarter: QUARTER(date) and pair with EXTRACT(YEAR FROM date) for year-scoped quarters\n",
      "   - Current date: CURRENT_DATE or CURDATE() (follow sql_context usage when present)\n",
      "3. Aggregates:\n",
      "   - Always alias aggregated columns (e.g., AS total_streams, AS avg_budget).\n",
      "   - Return only the columns requested (and any extra non-aggregated columns strictly required for grouping).\n",
      "4. GROUP BY:\n",
      "   - GROUP BY only the non-aggregated columns present in the SELECT.\n",
      "   - Avoid grouping by extra columns that change aggregation semantics.\n",
      "5. JOINs:\n",
      "   - Use explicit JOIN ... ON ... syntax.\n",
      "   - Use LEFT JOIN when the prompt says \"list all X and counts\" (so items with zero matches are included). Use INNER JOIN when only matching rows are required.\n",
      "6. Top-N patterns:\n",
      "   - Top N per group: use ROW_NUMBER() OVER (PARTITION BY group_col ORDER BY metric DESC) and then filter row_num <= N.\n",
      "   - Top N overall: use ORDER BY metric DESC LIMIT N.\n",
      "7. Date filtering:\n",
      "   - \"Last N months\": WHERE date_column >= DATE_SUB(CURRENT_DATE, INTERVAL N MONTH)\n",
      "   - Specific quarter/year: WHERE EXTRACT(YEAR FROM date_col) = 2021 AND QUARTER(date_col) = 1\n",
      "   - Use EXTRACT for months/years unless the sql_context suggests a different function.\n",
      "8. DISTINCT:\n",
      "   - Use DISTINCT only when explicitly required (e.g., counting distinct users or companies).\n",
      "9. Window and analytic functions:\n",
      "   - Use window functions for ranking/top-N and for running totals if required by the prompt.\n",
      "10. Aliases and readability:\n",
      "   - Use concise table aliases (e.g., FROM programs p JOIN categories c ON ...).\n",
      "   - Use meaningful aliases for aggregate columns.\n",
      "11. When prompt asks for \"create a table\" but sql_context already contains it, prefer CREATE TABLE IF NOT EXISTS with a schema consistent with sql_context (or ask whether to recreate/replace).\n",
      "12. Return minimal columns: do not return extra columns beyond what the prompt asks for (and those needed for correctness).\n",
      "\n",
      "Ambiguity, missing information, and clarifying questions\n",
      "- If the prompt is ambiguous (e.g., \"top 3 initiatives in Kenya, Tanzania and Uganda\" — unclear if top 3 per country or top 3 combined), ask one clarifying question before producing SQL.\n",
      "- If the prompt needs a column (e.g., \"department\") that does not exist in sql_context, ask a clarifying question.\n",
      "- If the prompt asks to delete/update rows but doesn't specify which row(s) (e.g., \"Delete a language\" without an identifier), ask which identifier/value to use.\n",
      "- Ask a clarifying question instead of guessing if date ranges, grouping scope, or country lists are underspecified.\n",
      "\n",
      "Common pitfalls to avoid (explicit)\n",
      "- Do not group by extra columns that will change aggregate results.\n",
      "- Do not write WHERE conditions that are impossible (e.g., WHERE country = 'USA' AND country = 'Canada').\n",
      "- Do not invent variable names or placeholders without context (e.g., WHERE id = language_id) — use literal values or ask for the value.\n",
      "- When counting items by type, confirm whether SUM(quantity) or COUNT(*) is intended based on the prompt; use SUM(quantity) to total inventory amounts and COUNT(*) to count rows.\n",
      "- For \"all X and counts\" include items with zero matches using LEFT JOIN.\n",
      "- When the schema includes views, treat them like tables unless the prompt asks to modify them.\n",
      "\n",
      "Response content requirements\n",
      "- Reasoning: 1–3 short sentences mentioning the join/group/filter/aggregation strategy and any assumptions.\n",
      "- SQL: a single SQL statement only (SELECT, INSERT, UPDATE, DELETE or CREATE TABLE if requested). The SQL should be syntactically consistent with the schema in sql_context and with the rules above.\n",
      "- Name aggregated columns with clear aliases (e.g., AS total_sales, AS avg_quantity).\n",
      "- If ordering is requested, include ORDER BY and, where applicable, LIMIT.\n",
      "\n",
      "Useful patterns (you may reuse these patterns when applicable)\n",
      "- Sum per group:\n",
      "  SELECT category, SUM(budget) AS total_budget\n",
      "  FROM programs\n",
      "  GROUP BY category;\n",
      "- Last N months:\n",
      "  WHERE donation_date >= DATE_SUB(CURRENT_DATE, INTERVAL 12 MONTH)\n",
      "- Top N per group:\n",
      "  SELECT *\n",
      "  FROM (\n",
      "    SELECT t.*, ROW_NUMBER() OVER (PARTITION BY country ORDER BY budget DESC) AS rn\n",
      "    FROM programs t\n",
      "  ) sub\n",
      "  WHERE rn <= 3;\n",
      "- Count distinct users on a date:\n",
      "  SELECT COUNT(DISTINCT user_id) AS num_users\n",
      "  FROM sessions\n",
      "  WHERE login_date = '2021-01-01';\n",
      "\n",
      "Be concise and precise. If you must ask a clarifying question, ask one clear question only.\n"
     ]
    }
   ],
   "source": [
    "print(optimized_program.predict.signature.instructions)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86f2a893",
   "metadata": {},
   "source": [
    "# Store Programs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6e93a5da",
   "metadata": {},
   "outputs": [],
   "source": [
    "program.save(\"./dspy_program/3.5_program.json\", save_program=False)\n",
    "optimized_program.save(\"./optimized_program/3.5_program.json\", save_program=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e85afb4",
   "metadata": {},
   "source": [
    "# Evals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "64245ba8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "from datasets import Dataset\n",
    "from time import perf_counter\n",
    "from typing import Dict, Any, Optional\n",
    "\n",
    "def evaluate_program(\n",
    "    program,\n",
    "    ds_test: Dataset,\n",
    "    limit: int = 100,\n",
    "    max_workers: int = 8,\n",
    "    field_map: Optional[Dict[str, str]] = None,\n",
    ") -> Dict[str, Any]:\n",
    "    \"\"\"\n",
    "    Evaluate a DSPy program on the first `limit` rows of a HF Dataset split.\n",
    "\n",
    "    Args:\n",
    "        program: a DSPy Module with signature program(sql_prompt=..., sql_context=...)\n",
    "        ds_test: Hugging Face Dataset (e.g., ds[\"test\"])\n",
    "        limit: number of rows to evaluate (default 100)\n",
    "        max_workers: parallel threads for I/O-bound LM + judge\n",
    "        field_map: optional mapping if your column names differ:\n",
    "                   {\"sql_prompt\": \"...\", \"sql_context\": \"...\", \"sql\": \"...\"}\n",
    "\n",
    "    Returns:\n",
    "        {\n",
    "          \"accuracy\": float,\n",
    "          \"correct\": int,\n",
    "          \"total\": int,\n",
    "          \"avg_latency_s\": float,\n",
    "          \"failures\": [ {idx, reason, pred_sql, feedback} ... up to 20 ],\n",
    "        }\n",
    "    \"\"\"\n",
    "    if field_map is None:\n",
    "        field_map = {\"sql_prompt\": \"sql_prompt\", \"sql_context\": \"sql_context\", \"sql\": \"sql\"}\n",
    "\n",
    "    n = min(limit, len(ds_test))\n",
    "    subset = ds_test.select(range(n))\n",
    "    start = perf_counter()\n",
    "\n",
    "    def _eval_one(i_row):\n",
    "        i, row = i_row\n",
    "        try:\n",
    "            pred = program(\n",
    "                sql_prompt=row[field_map[\"sql_prompt\"]],\n",
    "                sql_context=row[field_map[\"sql_context\"]],\n",
    "            )\n",
    "            pred_sql = getattr(pred, \"sql\", None) or (pred.get(\"sql\") if isinstance(pred, dict) else None) or \"\"\n",
    "            jr = judge(\n",
    "                sql_context=row[field_map[\"sql_context\"]],\n",
    "                sql_prompt=row[field_map[\"sql_prompt\"]],\n",
    "                golden_sql=row[field_map[\"sql\"]],\n",
    "                candidate_sql=pred_sql,\n",
    "            )\n",
    "            ok = bool(getattr(jr, \"similar\", False))\n",
    "            feedback = getattr(jr, \"reasoning\", \"\") or \"\"\n",
    "            return (i, ok, pred_sql, feedback, None)\n",
    "        except Exception as e:\n",
    "            return (i, False, \"\", \"\", f\"{type(e).__name__}: {e}\")\n",
    "\n",
    "    results = []\n",
    "    # Threaded evaluation (I/O bound: LM + judge). Tune max_workers to your provider limits.\n",
    "    with ThreadPoolExecutor(max_workers=max_workers) as ex:\n",
    "        futures = [ex.submit(_eval_one, (i, subset[i])) for i in range(n)]\n",
    "        for f in as_completed(futures):\n",
    "            results.append(f.result())\n",
    "\n",
    "    # Sort back to input order\n",
    "    results.sort(key=lambda x: x[0])\n",
    "\n",
    "    correct = sum(1 for _, ok, *_ in results if ok)\n",
    "    total = n\n",
    "    acc = correct / total if total else 0.0\n",
    "    elapsed = perf_counter() - start\n",
    "    avg_lat = elapsed / total if total else 0.0\n",
    "\n",
    "    failures = []\n",
    "    for i, ok, pred_sql, feedback, err in results:\n",
    "        if not ok and len(failures) < 20:\n",
    "            failures.append({\n",
    "                \"idx\": i,\n",
    "                \"reason\": (\"error: \" + err) if err else \"mismatch\",\n",
    "                \"pred_sql\": pred_sql,\n",
    "                \"feedback\": feedback,\n",
    "            })\n",
    "\n",
    "    return {\n",
    "        \"accuracy\": acc,\n",
    "        \"correct\": correct,\n",
    "        \"total\": total,\n",
    "        \"avg_latency_s\": avg_lat,\n",
    "        \"failures\": failures,\n",
    "    }\n",
    "    \n",
    "test_split = ds[\"test\"]\n",
    "test_split = test_split.shuffle()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6ca6e0ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Program: {'accuracy': 0.62, 'correct': 310, 'total': 500, 'avg_latency_s': 1.2531627955820004, 'failures': [{'idx': 1, 'reason': 'mismatch', 'pred_sql': \"SELECT SUM(m.revenue) AS total_revenue\\nFROM movie m\\nJOIN studio s ON m.studio_id = s.studio_id\\nWHERE s.name = 'Blue Studios'\", 'feedback': \"The candidate SQL query joins the `movie` table with the `studio` table on the `studio_id` column and then filters the rows where the studio name is 'Blue Studios'. This approach indirectly filters the movies produced by Blue Studios, but it's not the most direct and efficient way to accomplish the task because it involves an unnecessary join operation. The golden SQL query directly filters the movies by the `studio_id` associated with Blue Studios, which is a more efficient approach.\"}, {'idx': 2, 'reason': 'mismatch', 'pred_sql': 'SELECT \\n    SUM(rd.reclamation_cost) as total_reclamation_cost, \\n    es.employee_count as total_employees\\nFROM \\n    reclamation_data rd\\nJOIN \\n    employee_stats es ON rd.mine_id = es.mine_id\\nWHERE \\n    es.mine_id IN (\\n        SELECT mine_id \\n        FROM mine_employees \\n        WHERE mine_id IN (\\n            SELECT mine_id \\n            FROM employee_stats \\n            WHERE employee_count > 300\\n        )\\n    )\\nAND \\n    es.mine_id IN (\\n        SELECT mine_id \\n        FROM mine_employees \\n        WHERE mine_id IN (\\n            SELECT mine_id \\n            FROM production_data\\n        )\\n    )\\nAND \\n    es.mine_id IN (\\n        SELECT mine_id \\n        FROM production_data \\n        WHERE mine_id IN (\\n            SELECT mine_id \\n            FROM operation_duration\\n        )\\n    )\\nAND \\n    es.mine_id IN (\\n        SELECT mine_id \\n        FROM operation_duration\\n    )\\nAND \\n    es.mine_id IN (\\n        SELECT mine_id \\n        FROM reclamation_data\\n    )\\nAND \\n    es.mine_id IN (\\n        SELECT mine_id \\n        FROM reclamation_data \\n        WHERE mine_id IN (\\n            SELECT mine_id \\n            FROM operation_duration\\n        )\\n    )\\nAND \\n    es.mine_id IN (\\n        SELECT mine_id \\n        FROM reclamation_data \\n        WHERE mine_id IN (\\n            SELECT mine_id \\n            FROM production_data\\n        )\\n    )\\nGROUP BY \\n    es.mine_id\\nHAVING \\n    es.mine_id IN (\\n        SELECT mine_id \\n        FROM reclamation_data \\n        WHERE mine_id IN (\\n            SELECT mine_id \\n            FROM operation_duration\\n        )\\n    )\\nAND \\n    es.mine_id IN (\\n        SELECT mine_id \\n        FROM reclamation_data \\n        WHERE mine_id IN (\\n            SELECT mine_id \\n            FROM production_data\\n        )\\n    );', 'feedback': 'The candidate SQL query is not functionally similar to the golden SQL query. The candidate query includes multiple subqueries and conditions which are not necessary to achieve the desired result. It also lacks the proper aggregation and grouping to calculate the total reclamation cost and number of employees for mines in the South America region with more than 300 employees.'}, {'idx': 5, 'reason': 'mismatch', 'pred_sql': 'SELECT YEAR(P.SaleDate) AS Year, SUM(C.ClaimAmount) AS TotalClaimAmount\\nFROM Policies P\\nJOIN Claims C ON P.PolicyID = C.PolicyID\\nWHERE MONTH(P.SaleDate) BETWEEN 1 AND 3\\nGROUP BY YEAR(P.SaleDate);', 'feedback': 'The golden SQL query calculates the total claim amount for policies sold in the first quarter of each year by using the `DATEPART` function to extract the quarter from the `SaleDate` and then summing the `ClaimAmount`. It performs a join on the `PolicyID` between the `Claims` and `Policies` tables. The candidate SQL query attempts to achieve a similar result by extracting the year from `SaleDate` and summing `ClaimAmount`, but it filters the data based on the month between 1 and 3, which may not cover only the first quarter for each year. Additionally, the grouping is done by year in the candidate query, instead of by quarter.'}, {'idx': 7, 'reason': 'mismatch', 'pred_sql': 'SELECT country_id, MAX(year_preserved) AS max_years_preserved\\nFROM art_forms\\nGROUP BY country_id;', 'feedback': 'The golden SQL query retrieves the maximum number of years a traditional art form has been preserved in each country by joining the `countries` and `art_forms` tables on the `id` and `country_id` columns respectively. It then uses the `MAX` function to find the highest value of `year_preserved` for each country group. On the other hand, the candidate SQL query only selects the `country_id` and calculates the maximum `year_preserved` without considering the country names or joining the tables.'}, {'idx': 12, 'reason': 'mismatch', 'pred_sql': \"UPDATE recycling_initiatives\\nSET initiative_type = 'Metal Recycling'\\nWHERE year = 2022 AND city = 'Paris';\", 'feedback': \"The golden SQL query updates the initiative_type to 'Composting' for recycling initiatives in Paris in 2022, while the candidate SQL query updates the initiative_type to 'Metal Recycling' for the same matching criteria. The candidate query is not functionally similar to the golden query because they update the initiative_type to different values.\"}, {'idx': 20, 'reason': 'mismatch', 'pred_sql': 'SELECT Country, SUM(Operations) AS TotalOperations\\nFROM PeacekeepingOperations\\nGROUP BY Country\\nORDER BY TotalOperations DESC;', 'feedback': 'The golden SQL query calculates the total number of peacekeeping operations conducted by each country with a running total, and then ranks the countries based on the total operations. It correctly uses the window function with partitioning by country and ordering by year. The candidate SQL query only calculates the total operations per country without considering the running total or ranking.'}, {'idx': 26, 'reason': 'mismatch', 'pred_sql': \"INSERT INTO audience (visitor_id, name, country, visit_date) VALUES (DEFAULT, 'Alex', 'USA', CURRENT_DATE);\", 'feedback': 'The candidate SQL query uses the `DEFAULT` keyword to automatically generate a value for the `visitor_id` field, whereas the golden SQL query calculates the `visitor_id` by selecting the maximum existing id and adding 1 to it. Additionally, the candidate SQL query uses `CURRENT_DATE` instead of `CURDATE()` for the `visit_date` field.'}, {'idx': 28, 'reason': 'mismatch', 'pred_sql': 'SELECT *\\nFROM subscribers\\nWHERE last_data_usage_date >= DATE_SUB(LAST_DAY(NOW()), INTERVAL 1 MONTH) + INTERVAL 1 DAY\\nAND monthly_data_usage = 0.0;', 'feedback': 'The golden SQL query retrieves mobile subscribers who have not used any data in the last month by checking for monthly_data_usage equal to 0 and last_data_usage_date being within the last month. On the other hand, the candidate SQL query attempts to achieve the same result by checking if the last_data_usage_date is greater than or equal to the beginning of the last month and if the monthly_data_usage is 0.0. Both queries have different approaches to identifying subscribers who have not used any data in the last month.'}, {'idx': 31, 'reason': 'mismatch', 'pred_sql': 'SELECT SiteID, COUNT(DISTINCT ObjectType) AS UniqueArtifactTypes\\nFROM Artifact\\nGROUP BY SiteID;', 'feedback': 'The golden SQL query retrieves the count of unique artifact types for each excavation site by joining the ExcavationSite and Artifact tables on SiteID and then grouping the results by SiteName. On the other hand, the candidate SQL query only counts the unique artifact types for each site directly from the Artifact table without considering the ExcavationSite table. Therefore, the candidate query does not provide the desired output as it misses the join condition and the grouping by SiteName.'}, {'idx': 33, 'reason': 'mismatch', 'pred_sql': 'SELECT\\n    Country,\\n    LaunchDate AS CurrentLaunchDate,\\n    LAG(LaunchDate) OVER (PARTITION BY Country ORDER BY LaunchDate) AS PreviousLaunchDate,\\n    DATEDIFF(LaunchDate, LAG(LaunchDate) OVER (PARTITION BY Country ORDER BY LaunchDate)) AS DaysBetweenLaunches\\nFROM\\n    SatelliteLaunches\\nORDER BY\\n    Country, LaunchDate;', 'feedback': 'The candidate SQL query calculates the difference between the current launch date and the previous launch date using the LAG window function. The logic is slightly different from the golden SQL query, which uses the LEAD window function to find the next launch date. Additionally, the candidate SQL query does not properly calculate the number of days between launches. Therefore, the candidate query does not fulfill the requirements of the prompt.'}, {'idx': 35, 'reason': 'mismatch', 'pred_sql': \"SELECT \\n    CONCAT(MONTH(date), '-', YEAR(date)) AS month_year,\\n    AVG(temperature - LAG(temperature, 1) OVER (PARTITION BY MONTH(date) ORDER BY date)) AS avg_temperature_change\\nFROM \\n    WeatherData\\nWHERE \\n    location = 'Arctic' AND YEAR(date) = 2020\\nGROUP BY \\n    MONTH(date), YEAR(date)\\nORDER BY \\n    YEAR(date), MONTH(date);\", 'feedback': 'The golden SQL query calculates the average temperature in the Arctic region by month for the year 2020 using the `AVG()` function and `GROUP BY` clause, filtering the data based on the location and year. The candidate SQL query, on the other hand, calculates the average temperature change in the Arctic region by month for the year 2020 using the difference of temperatures in consecutive rows within the same month. This difference is calculated with the `AVG(temperature - LAG(temperature, 1) OVER (PARTITION BY MONTH(date) ORDER BY date))` expression.'}, {'idx': 37, 'reason': 'mismatch', 'pred_sql': 'SELECT year, COUNT(*) AS total_grants\\nFROM research_grants\\nGROUP BY year;', 'feedback': 'The golden SQL query calculates the sum of the amount for each year by grouping the results based on the year. On the other hand, the candidate SQL query counts the total number of grants per year by grouping the results based on the year. Both queries provide different aggregate calculations for research grants per year.'}, {'idx': 38, 'reason': 'mismatch', 'pred_sql': 'SELECT Site_Name, Number_of_Artifacts\\nFROM Excavation_Sites;', 'feedback': 'The golden SQL query retrieves the `Site_ID` and `Site_Name` along with the total number of artifacts found at each excavation site by summing up the `Number_of_Artifacts` for each group. On the other hand, the candidate SQL query only selects the `Site_Name` and `Number_of_Artifacts` fields without performing any aggregation.'}, {'idx': 41, 'reason': 'mismatch', 'pred_sql': \"SELECT AVG(mh.score) AS average_mental_health_score\\nFROM teachers t\\nJOIN mental_health mh ON t.id = mh.teacher_id\\nWHERE t.gender = 'Male';\", 'feedback': 'The candidate SQL query is not functionally similar to the golden SQL query. Although both queries aim to calculate the average mental health score for male teachers, they differ in the table names being used and the column selected for averaging. The golden SQL query correctly joins the `teachers` and `teacher_mental_health` tables and selects the `mental_health_score` column for averaging, while the candidate SQL query mistakenly uses `mental_health` table and selects the `score` column for averaging.'}, {'idx': 42, 'reason': 'mismatch', 'pred_sql': 'SELECT county_id\\nFROM (\\n    SELECT county_id, year, cost,\\n           ROW_NUMBER() OVER (PARTITION BY county_id ORDER BY year) as row_num\\n    FROM costs\\n    WHERE year >= YEAR(CURRENT_DATE) - 3\\n) ranked\\nGROUP BY county_id\\nHAVING COUNT(*) = 4\\nAND MIN(cost) < MAX(cost)', 'feedback': 'The golden SQL query correctly identifies counties in New Mexico with increasing healthcare costs over the past 4 years by using window functions to track the order of costs over the years. It ensures that all 4 consecutive years have increasing costs for each county, and restricts the results to only those counties in New Mexico. On the other hand, the candidate SQL query attempts to identify counties with 4 consecutive years of data within the last 3 years, but it does not explicitly check for increasing costs over the years as required in the prompt. It only checks if the minimum cost is less than the maximum, which does not guarantee a continuous increase over the 4 years.'}, {'idx': 43, 'reason': 'mismatch', 'pred_sql': 'SELECT regions.region_id, regions.region_name, SUM(timber_harvest.volume) AS total_volume\\nFROM regions\\nJOIN timber_harvest ON regions.region_id = timber_harvest.region_id\\nGROUP BY regions.region_id, regions.region_name;', 'feedback': 'The golden SQL query correctly joins the tables `regions` and `timber_harvest` on the `region_id` column and groups the result by `region_name`, providing the total volume of timber harvested by each region. The candidate SQL query also correctly joins the tables on `region_id` but groups by `region_id` and `region_name`, which might result in different grouping outcomes as compared to the golden query.'}, {'idx': 44, 'reason': 'mismatch', 'pred_sql': \"INSERT INTO DefenseProjectTimelines (id, project_name, negotiation_start_date, negotiation_end_date, country)\\nVALUES (1, 'Type 16 MCV', '2022-04-01', '2024-04-01', 'Thailand');\", 'feedback': \"The candidate SQL query is adding a specific value for the 'id' column, which is defined as the primary key and auto-incremented in the table schema. The golden SQL query does not include the 'id' column in the column list as it is automatically generated.\"}, {'idx': 45, 'reason': 'mismatch', 'pred_sql': \"SELECT AVG(CASE WHEN category = 'Malware' THEN severity END) AS average_severity\\nFROM vulnerabilities;\", 'feedback': \"The golden SQL query calculates the average severity for each level ('Critical', 'High', 'Medium', 'Low') within the 'Malware' category by assigning weights to each severity level. The candidate SQL query, on the other hand, calculates the average severity without taking into account the different severity levels. It only considers the severity when the category is 'Malware'.\"}, {'idx': 47, 'reason': 'mismatch', 'pred_sql': \"SELECT cause\\nFROM donor_location\\nWHERE country = 'United States' OR country = 'Canada'\\nGROUP BY cause\\nHAVING COUNT(DISTINCT country) = 2;\", 'feedback': 'The golden SQL query retrieves the causes that received funding from donors in both the United States and Canada by using the INTERSECT operator to find the common causes between the two countries. On the other hand, the candidate SQL query retrieves the causes that received funding from donors in either the United States or Canada and then filters the results to only include causes where the distinct count of countries is equal to 2. This approach does not guarantee that the causes received funding from both countries.'}, {'idx': 51, 'reason': 'mismatch', 'pred_sql': \"SELECT project_name\\nFROM accessibility.research\\nWHERE (project_name LIKE '%AI%' OR project_name LIKE '%Accessibility%')\\nAND (region = 'EU' OR region = 'Africa');\", 'feedback': \"The candidate SQL query retrieves project names that contain either 'AI' or 'Accessibility' and are in either 'EU' or 'Africa'. This query does not specifically find the intersection of AI and accessibility research projects in the EU and Africa as requested.\"}]}\n"
     ]
    }
   ],
   "source": [
    "og_metrics = evaluate_program(program, test_split, limit=500, max_workers=32)\n",
    "print(f\"Original Program: {og_metrics}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e2fdea35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Program: {'accuracy': 0.62, 'correct': 310, 'total': 500, 'avg_latency_s': 0.1289489997500059, 'failures': [{'idx': 2, 'reason': 'mismatch', 'pred_sql': 'SELECT rd.mine_id, SUM(rd.reclamation_cost) AS total_reclamation_cost, es.employee_count AS total_employees\\nFROM reclamation_data rd\\nJOIN employee_stats es ON rd.mine_id = es.mine_id\\nWHERE es.employee_count > 300\\nGROUP BY rd.mine_id;', 'feedback': 'The candidate SQL query is filtering mines with more than 300 employees from the `employee_stats` view and calculating the total reclamation cost for those mines from the `reclamation_data` table. However, the candidate SQL query does not include the condition for mines with more than 5 years of operation as the golden SQL query does.'}, {'idx': 5, 'reason': 'mismatch', 'pred_sql': 'SELECT EXTRACT(YEAR FROM p.SaleDate) AS SaleYear, SUM(c.ClaimAmount) AS TotalClaimAmount\\nFROM Policies p\\nJOIN Claims c ON p.PolicyID = c.PolicyID\\nWHERE EXTRACT(MONTH FROM p.SaleDate) BETWEEN 1 AND 3\\nGROUP BY EXTRACT(YEAR FROM p.SaleDate);', 'feedback': 'The golden SQL query calculates the total claim amount for policies sold in the first quarter of each year by using the `PARTITION BY` and `DATEPART` functions to group the data by quarters and filter for the first quarter. On the other hand, the candidate SQL query calculates the total claim amount for policies sold between January and March of each year by extracting the year and month from the sale date and filtering for months 1 to 3. Both queries join the `Claims` and `Policies` tables on the `PolicyID` and perform the necessary aggregation. The key difference lies in how the quarters are handled in the filtering condition.'}, {'idx': 7, 'reason': 'mismatch', 'pred_sql': 'SELECT c.name AS country, MAX(af.year_preserved) AS max_years_preserved\\nFROM countries c\\nLEFT JOIN art_forms af ON c.id = af.country_id\\nGROUP BY c.name;', 'feedback': \"The golden SQL query selects the country name and the maximum number of years a traditional art form has been preserved for each country by joining the 'countries' and 'art_forms' tables on the country_id. It then groups the results by the country's id. \\nThe candidate SQL query also aims to find the maximum number of years a traditional art form has been preserved in each country by joining the 'countries' and 'art_forms' tables on the country_id. However, it aliases the selected columns differently ('c.name' and 'af.year_preserved'), groups by 'c.name' instead of 'c.id', and uses a LEFT JOIN instead of an INNER JOIN.\"}, {'idx': 12, 'reason': 'mismatch', 'pred_sql': \"UPDATE recycling_initiatives\\nSET initiative_type = 'Metal Recycling'\\nWHERE year = 2022 AND city = 'Paris';\", 'feedback': \"The golden SQL query updates the initiative_type to 'Composting' for recycling initiatives in Paris in 2022, while the candidate SQL query updates the initiative_type to 'Metal Recycling' for the same matching criteria. The candidate query is not functionally similar to the golden query because they update the initiative_type to different values.\"}, {'idx': 19, 'reason': 'mismatch', 'pred_sql': 'SELECT m.name, COUNT(t.officer_id) AS num_trainings\\nFROM mental_health_parity_officers m\\nLEFT JOIN trainings_conducted t ON m.officer_id = t.officer_id\\nGROUP BY m.name;', 'feedback': 'The candidate SQL query joins the tables using a LEFT JOIN instead of an INNER JOIN like in the golden SQL query. This means that the candidate query will include all records from the \"mental_health_parity_officers\" table, even if there are no matching records in the \"trainings_conducted\" table. The candidate query also aliases the tables differently than the golden SQL query.'}, {'idx': 20, 'reason': 'mismatch', 'pred_sql': 'SELECT Country, SUM(Operations) AS Total_Operations\\nFROM PeacekeepingOperations\\nGROUP BY Country\\nORDER BY Total_Operations DESC;', 'feedback': 'The candidate SQL query simply calculates the sum of operations for each country without considering the ranking from highest to lowest. It also does not utilize window functions like the golden SQL query to achieve the desired ranking based on total operations.'}, {'idx': 21, 'reason': 'mismatch', 'pred_sql': 'SELECT h.country, SUM(h.events) AS total_events\\nFROM Humanitarian_Assistance h\\nWHERE h.year >= YEAR(CURRENT_DATE) - 2\\nGROUP BY h.country;', 'feedback': 'The golden SQL query calculates the total number of humanitarian assistance events by each country in the last 3 years by joining the Humanitarian_Assistance and Countries tables and filtering the data based on the year. It correctly groups the results by country name. \\nThe candidate SQL query also calculates the total number of events by each country; however, it filters the data based on the last 2 years instead of the last 3 years. This difference in the filter condition makes the candidate query functionally different from the golden query.'}, {'idx': 26, 'reason': 'mismatch', 'pred_sql': \"INSERT INTO audience (visitor_id, name, country, visit_date) \\nVALUES (DEFAULT, 'Alex', 'USA', CURRENT_DATE);\", 'feedback': 'The candidate SQL query and the golden SQL query both aim to insert a new record into the \"audience\" table for a visitor named \"Alex\" from the USA. However, there are differences in how the new visitor_id value is generated and the date value is obtained.'}, {'idx': 28, 'reason': 'mismatch', 'pred_sql': \"SELECT *\\nFROM subscribers\\nWHERE last_data_usage_date < DATE_SUB(DATE_FORMAT(CURRENT_DATE, '%Y-%m-01'), INTERVAL 1 MONTH);\", 'feedback': \"The golden SQL query retrieves the `id`, `last_data_usage_date`, and `monthly_data_usage` columns from the `subscribers` table where the `monthly_data_usage` is 0 and the `last_data_usage_date` is within the last month. It accurately filters subscribers who have not used any data in the last month by comparing the `monthly_data_usage` and the date of last data usage.\\n\\nThe candidate SQL query also aims to find subscribers who have not used any data in the last month. However, it uses a different approach by comparing the `last_data_usage_date` with the first day of the previous month to identify those subscribers. This approach may not be as accurate as the golden query in determining the last month's data usage status for each subscriber.\"}, {'idx': 31, 'reason': 'mismatch', 'pred_sql': 'SELECT SiteID, COUNT(DISTINCT ObjectType) AS num_unique_artifact_types\\nFROM Artifact\\nGROUP BY SiteID;', 'feedback': 'The golden SQL query joins the ExcavationSite and Artifact tables on the SiteID, groups the results by SiteName, and counts the distinct ObjectTypes to find the unique artifact types at each excavation site. On the other hand, the candidate SQL query only counts the distinct ObjectTypes grouped by SiteID from the Artifact table without joining the ExcavationSite table.'}, {'idx': 33, 'reason': 'mismatch', 'pred_sql': 'SELECT \\n    LaunchID,\\n    Country,\\n    LaunchDate,\\n    LaunchDate - LAG(LaunchDate, 1) OVER(PARTITION BY Country ORDER BY LaunchDate) AS DaysSincePreviousLaunch\\nFROM \\n    SatelliteLaunches\\nORDER BY \\n    Country, LaunchDate;', 'feedback': 'The golden SQL query calculates the difference in launch dates for each pair of consecutive satellite launches by country using the LEAD function to get the next launch date. It then calculates the number of days between the launches using the DATEDIFF function. On the other hand, the candidate SQL query attempts to calculate the days since the previous launch using the LAG function, which is not the same as determining the difference between consecutive launches.'}, {'idx': 35, 'reason': 'mismatch', 'pred_sql': \"SELECT EXTRACT(MONTH FROM date) AS month,\\n       AVG(temperature - LAG(temperature) OVER(PARTITION BY location ORDER BY date)) AS avg_temp_change\\nFROM WeatherData\\nWHERE location = 'Arctic'\\nAND EXTRACT(YEAR FROM date) = 2020\\nGROUP BY EXTRACT(MONTH FROM date);\", 'feedback': \"The golden SQL query calculates the average temperature in the Arctic region by month for the year 2020 by directly averaging the temperatures with the location and year filters applied. On the other hand, the candidate SQL query attempts to calculate the average temperature change in the Arctic region by month for the year 2020 by subtracting the previous temperature from the current one and then finding the average. The candidate SQL query is not directly calculating the average temperature and temperature change without considering the previous temperature value which doesn't align with the user's original request.\"}, {'idx': 37, 'reason': 'mismatch', 'pred_sql': 'SELECT year, COUNT(*) AS total_grants\\nFROM research_grants\\nGROUP BY year;', 'feedback': 'The golden SQL query calculates the sum of the amount for each year by grouping the results based on the year. On the other hand, the candidate SQL query counts the total number of grants per year by grouping the results based on the year. Both queries provide different aggregate calculations for research grants per year.'}, {'idx': 38, 'reason': 'mismatch', 'pred_sql': 'SELECT Site_Name, SUM(Number_of_Artifacts) AS Total_Artifacts\\nFROM Excavation_Sites\\nGROUP BY Site_Name;', 'feedback': 'The golden SQL query is selecting the `Site_ID`, `Site_Name`, and the sum of `Number_of_Artifacts` grouped by `Site_ID` and `Site_Name`, which provides the number of artifacts found in each excavation site. The candidate SQL query is selecting the `Site_Name` and the sum of `Number_of_Artifacts` grouped by `Site_Name`. The main difference is that the golden SQL query includes the `Site_ID` in the selection and grouping, providing a more detailed breakdown of artifacts per site compared to the candidate SQL query.'}, {'idx': 41, 'reason': 'mismatch', 'pred_sql': \"SELECT gender, AVG(mental_health_score) AS avg_mental_health_score\\nFROM teachers\\nWHERE gender = 'Male'\\nGROUP BY gender;\", 'feedback': 'The candidate SQL query calculates the average mental health score only for male teachers by filtering the records based on the gender column. It then groups the results by the gender column, which does not serve any practical purpose in this case. On the other hand, the golden SQL query correctly calculates the average mental health score for male teachers by joining the teachers table with the teacher_mental_health table on teacher id and filtering only the male teachers before calculating the average.'}, {'idx': 42, 'reason': 'mismatch', 'pred_sql': 'SELECT DISTINCT c1.county_id\\nFROM costs c1\\nJOIN costs c2 ON c1.county_id = c2.county_id AND c1.year = c2.year + 4\\nWHERE c1.year = (SELECT MAX(year) FROM costs WHERE county_id = c1.county_id)\\nAND c1.cost > c2.cost;', 'feedback': \"The golden SQL query uses a window function to calculate the change in costs over 4 years for each county in New Mexico, ensuring that there are exactly 4 consecutive years with increasing costs. It also filters the results based on the state being 'New Mexico'. On the other hand, the candidate SQL query joins the costs table on itself to compare costs between the current year and the year 4 years prior for each county, without considering consecutive years or filtering by state. Therefore, the candidate query does not accurately identify counties with increasing healthcare costs in New Mexico over the past 4 years.\"}, {'idx': 43, 'reason': 'mismatch', 'pred_sql': 'SELECT r.region_id, r.region_name, SUM(th.volume) AS total_volume\\nFROM regions r\\nJOIN timber_harvest th ON r.region_id = th.region_id\\nGROUP BY r.region_id, r.region_name;', 'feedback': 'The candidate SQL query selects the region_id along with the region_name, and calculates the total volume of timber harvested by each region. The JOIN condition between the two tables is based on region_id. However, in the golden SQL query, the region_name is selected instead of the region_id, and the GROUP BY clause is based on region_name.'}, {'idx': 45, 'reason': 'mismatch', 'pred_sql': \"SELECT AVG(severity) AS average_severity\\nFROM vulnerabilities\\nWHERE category = 'Malware';\", 'feedback': \"The golden SQL query calculates the weighted average of severity levels in the 'Malware' category based on specific severity levels, while the candidate SQL query calculates the simple average of severity levels in the 'Malware' category.\"}, {'idx': 47, 'reason': 'mismatch', 'pred_sql': \"SELECT d1.cause\\nFROM donor_location d1\\nJOIN donor_location d2 ON d1.cause = d2.cause\\nWHERE d1.country = 'United States' AND d2.country = 'Canada';\", 'feedback': 'The golden SQL query uses the INTERSECT operator to find the causes that received funding from donors in both the United States and Canada. It correctly retrieves the causes based on the country criteria separately and then intersects the results. On the other hand, the candidate SQL query attempts to achieve the same result through a self-join on the table based on the cause, which may not yield the correct intersection of causes.'}, {'idx': 48, 'reason': 'mismatch', 'pred_sql': \"SELECT region, SUM(quantity) AS total_offshore_drilling_platforms\\nFROM InfrastructureData\\nWHERE platform_type = 'offshore_drilling'\\nAND region IN ('North Sea', 'Gulf of Mexico')\\nGROUP BY region;\", 'feedback': \"The golden SQL query calculates the total number of offshore drilling platforms in the North Sea and Gulf of Mexico by summing the quantities where the region is 'North Sea' and platform_type is 'offshore_drilling', or where the region is 'Gulf of Mexico' and platform_type is 'offshore_drilling'. \\nThe candidate SQL query calculates the total offshore drilling platforms for regions 'North Sea' and 'Gulf of Mexico' without specifying the platform type in the WHERE clause. It also groups the results by region.\"}]}\n"
     ]
    }
   ],
   "source": [
    "opt_metrics = evaluate_program(optimized_program, test_split, limit=500, max_workers=32)\n",
    "print(f\"Original Program: {opt_metrics}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9937eb78",
   "metadata": {},
   "source": [
    "# Store Eval Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fcc020d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "def save_metrics(metrics, path):\n",
    "    with open(path, \"w\") as f:\n",
    "        json.dump(metrics, f, indent=4, sort_keys=True) \n",
    "\n",
    "save_metrics(og_metrics, \"./dspy_program/3.5-turbo.json\")\n",
    "save_metrics(opt_metrics,\"./optimized_program/3.5-turbo.json\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
